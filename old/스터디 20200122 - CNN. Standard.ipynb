{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파이토치\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "import argparse\n",
    "import time\n",
    "from copy import deepcopy\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class View(nn.Module):\n",
    "    \n",
    "    def __init__(self, *shape): # 몇 개의 shape이 들어오든 상관이 없다, *이 하나면 tuple, 두개면 딕셔너리 형태로 저장\n",
    "        super(View, self).__init__()\n",
    "        self.shape = shape\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x.view(x.shape[0], *self.shape) # x.shape = [batch_size, channel, width, height]\n",
    "    \n",
    "    # x.view가 resize - 차원을 바꿔준다. 파이토치의 데이터가 기본적으로 [batch_size, channel, width, height] 이런 형태를 띠고 있다.\n",
    "    # View(-1) = x.shape[0], *self.shape:  batch_size, 그리고 나머지라는 뜻\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__() # super: nn.Module 클래스를 상속받는다\n",
    "        \n",
    "        layers = []\n",
    "        \n",
    "        layers += [nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=1, padding=1),\n",
    "                  nn.ReLU(inplace=True), # relu를 통과한 값이 갱신되도록 해주는게 inplace=True\n",
    "                  nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "                  nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "                  nn.ReLU(inplace=True),\n",
    "                  nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "                  View(-1), # 우리가 봤을 땐 1차원인 데이터를 컴퓨터는 4차원으로 보기 때문에 그걸 해결하기 위함\n",
    "                  nn.Linear(in_features=3136, out_features=128), # out_feature는 내 맘, 3136 = 64*7*7\n",
    "                  nn.ReLU(inplace=True),\n",
    "                  nn.Linear(in_features=128, out_features=10),\n",
    "                  nn.ReLU(inplace=True)]\n",
    "        \n",
    "        self.layers = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./datasets\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcfebae2acbe4deba00523433a86d8fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./datasets\\MNIST\\raw\\train-images-idx3-ubyte.gz to ./datasets\\MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./datasets\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a9c23b5208545298697e39e6f79b27a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./datasets\\MNIST\\raw\\train-labels-idx1-ubyte.gz to ./datasets\\MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./datasets\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34f6205b5da04a3c976368cf821e1c55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./datasets\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./datasets\\MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./datasets\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65c479c856b4462eab84ea19ab8319b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./datasets\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./datasets\\MNIST\\raw\n",
      "Processing...\n",
      "Done!\n",
      "Device :  cpu\n",
      "Epoch 0, acc(train/val) 38.21114/43.34936. Took 173.11 sec\n",
      "Epoch 1, acc(train/val) 49.47750/55.60897. Took 173.78 sec\n",
      "Epoch 2, acc(train/val) 58.30329/64.38301. Took 173.65 sec\n",
      "Epoch 3, acc(train/val) 68.86518/71.79487. Took 172.87 sec\n",
      "Epoch 4, acc(train/val) 70.91847/70.32252. Took 176.82 sec\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# MNIST 데이터에 대해서 훈련 및 검증\n",
    "\n",
    "# initial parameters\n",
    "\n",
    "seed = 6 # weight 초깃값 설정: 이렇게 설정해주면 돌릴때마다 weight 안변함\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "args = parser.parse_args('')\n",
    "args.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "args.batch_size = 256\n",
    "args.model = CNN()\n",
    "args.loss_fn = nn.CrossEntropyLoss()\n",
    "args.lr = 0.01\n",
    "args.epoch = 5\n",
    "\n",
    "#데이터 준비\n",
    "\n",
    "train_datasets = MNIST(root='./datasets', train=True, transform=ToTensor(), download=True)\n",
    "validation_datasets = MNIST(root='./datasets', train=False, transform=ToTensor(), download=True)\n",
    "\n",
    "# .item = 그 값을 가져온다\n",
    "# eq = pred 된 값 중 가장 확률 큰 값이랑 true 값이랑 얼마나 같으냐\n",
    "\n",
    "def acc(y_pred, y_true, batch_size):\n",
    "    accuracy = torch.sum(torch.eq(torch.argmax(y_pred, dim=1), y_true)).item() / batch_size * 100 \n",
    "    return accuracy\n",
    "\n",
    "def train(model, datasets, optimizer, loss_fn, args):\n",
    "    trainloader = DataLoader(dataset=datasets,\n",
    "                             batch_size=args.batch_size,\n",
    "                             shuffle=True,\n",
    "                             drop_last=True) # drop_last: 데이터는 6만개인데 배치사이즈가 256이면 딱 안나눠지니까 나머지는 떨구는 것\n",
    "    model.train() # 이번 모델은 train에 쓰겠다\n",
    "    model.zero_grad()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    train_acc = 0.0\n",
    "\n",
    "    for i, (X, y) in enumerate (trainloader): # 데이터를 만들어주는 것\n",
    "        X = X.to(args.device)\n",
    "        y_true = y.to(args.device)\n",
    "        y_pred = model(X)\n",
    "        loss = loss_fn(y_pred, y_true)\n",
    "        accuracy = acc(y_pred=y_pred, y_true= y_true, batch_size=args.batch_size)\n",
    "\n",
    "        model.zero_grad() # 초기화하라\n",
    "        optimizer.zero_grad() # 초기화하라\n",
    "        loss.backward() # 로스 (오류) 역전파해라\n",
    "        optimizer.step() # 옵티마이저는 가중치를 갱신하라\n",
    "\n",
    "        train_acc += accuracy\n",
    "\n",
    "    train_acc = train_acc / len(trainloader)\n",
    "\n",
    "    return train_acc\n",
    "\n",
    "def validate(model, datasets, args):\n",
    "    valloader = DataLoader(dataset=datasets,\n",
    "                             batch_size=args.batch_size,\n",
    "                             shuffle=False,\n",
    "                             drop_last=True)\n",
    "    model.eval() # 이번 모델은 val에 쓰겠다\n",
    "\n",
    "    val_acc = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (X, y) in enumerate(valloader):\n",
    "            X = X.to(args.device)\n",
    "            y_true = y.to(args.device)\n",
    "            y_pred = model(X)\n",
    "\n",
    "            accuracy = acc(y_pred=y_pred, y_true=y_true, batch_size=args.batch_size)\n",
    "            val_acc += accuracy\n",
    "\n",
    "    val_acc = val_acc / len(valloader)\n",
    "\n",
    "    return val_acc\n",
    "\n",
    "def training(train_datasets, val_datasets, args):\n",
    "    model = args.model\n",
    "    model.to(args.device)\n",
    "\n",
    "    print('Device : ', args.device)\n",
    "\n",
    "    loss_fn = args.loss_fn\n",
    "    optimizer = optim.SGD(model.parameters(), lr=args.lr) # 모델의 parameter들과 learnig rate를 참고해라\n",
    "\n",
    "    epoch_list = []\n",
    "    train_acc_list = []\n",
    "    val_acc_list = []\n",
    "\n",
    "    for epoch in range(args.epoch):\n",
    "        ts = time.time()\n",
    "\n",
    "        train_acc = train(model=model, datasets=train_datasets, optimizer=optimizer, loss_fn=loss_fn, args=args)\n",
    "        val_acc = validate(model=model, datasets=val_datasets, args=args)\n",
    "\n",
    "        te = time.time()\n",
    "\n",
    "        train_acc_list.append(train_acc)\n",
    "        val_acc_list.append(val_acc)\n",
    "        epoch_list.append(epoch)\n",
    "        print('Epoch {}, acc(train/val) {:2.5f}/{:2.5f}. Took {:2.2f} sec'.format(epoch,train_acc,val_acc,te - ts))                                                                                                                                                             \n",
    "                                                                                 \n",
    "    plt.title('CNN')\n",
    "    plt.plot(epoch_list, train_acc_list)\n",
    "    plt.plot(epoch_list, val_acc_list)\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend(['Train', 'Validation'])\n",
    "    plt.show()\n",
    "\n",
    "    torch.save(model.state_dict(), 'CNN.pt') # 모델의 가중치 상태를 dict형태로 저장\n",
    "\n",
    "# 모델 훈련시키기\n",
    "    \n",
    "training(train_datasets, validation_datasets, deepcopy(args))\n",
    "\n",
    "# model = CNN()\n",
    "# model.load_stat_dict(torch.load('CNN.pt'))를 쓰면 원래 사용하던 모델을 불러와서 이어서 쓸 수 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 케라스\n",
    "\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conv 레이어 계산 실험\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(Conv2D(input_shape = (112,112,1), filters = 64, kernel_size = (7,7), strides = 2, padding = 'same'))\n",
    "print(model.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_9 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 128)               401536    \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 421,642\n",
      "Trainable params: 421,642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-c5325c62eb5e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# inputs = Input(shape=(28,28,1), name = '~~') 하면 summary했을때 내가 지정한 name으로 설정됨\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# validation_split: 훈련셋에서 10프로만 val로 만든다,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# [loss, acc]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\venv\\lib\\site-packages\\keras-2.3.1-py3.7.egg\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1239\u001b[1;33m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[0;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\venv\\lib\\site-packages\\keras-2.3.1-py3.7.egg\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[0;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\venv\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3738\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3739\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3740\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3742\u001b[0m     \u001b[1;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\venv\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1079\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1080\u001b[0m     \"\"\"\n\u001b[1;32m-> 1081\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1082\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1083\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\venv\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1119\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[0;32m   1120\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[1;32m-> 1121\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\venv\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1222\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[1;32m-> 1224\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1225\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\venv\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 511\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    512\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\venv\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Sequential 없이도 모델 만드는 방법\n",
    "\n",
    "inputs = Input(shape=(28,28,1))\n",
    "conv = Conv2D(filters=32, kernel_size = (3,3), strides=(1,1), padding='same')(inputs)\n",
    "activation = Activation('relu')(conv) # same이 제로패딩, stride 기본값이 (1,1)\n",
    "maxpooling = MaxPooling2D(pool_size=(2,2))(activation)\n",
    "dropout = Dropout(0.5)(maxpooling)\n",
    "conv = Conv2D(filters=64, kernel_size=(3,3),strides=(1,1), padding='same', activation='relu')(maxpooling)\n",
    "maxpooling = MaxPooling2D(pool_size=(2,2))(conv)\n",
    "dropout = Dropout(0.5)(maxpooling)\n",
    "flatten = Flatten()(dropout)\n",
    "dense = Dense(128, activation = 'relu')(flatten)\n",
    "outputs = Dense(num_classes, activation='softmax')(dense)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.summary() # inputs = Input(shape=(28,28,1), name = '~~') 하면 summary했을때 내가 지정한 name으로 설정됨\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mnist 데이터 준비\n",
    "\n",
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "\n",
    "width = 28\n",
    "height = 28\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(60000, width, height, 1).astype('float32')/255.0\n",
    "x_test = x_test.reshape(10000, width, height, 1).astype('float32')/255.0\n",
    "\n",
    "num_classes = 10\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 훈련\n",
    "\n",
    "# 한 에폭에 100번 돌고 (훈련데이터 54000개 = 배치사이즈 540*100) 그걸 전체 10번 반복\n",
    "# validation_split: 훈련셋에서 10프로만 val로 만든다, \n",
    "\n",
    "# model.fit_generator와는 조금 다르다: 거기엔 steps_per_epoch가 들어가고 그 변수 자체에 batch size의 표현이 내재되어 있다.\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=540, epochs=10, verbose = 2, validation_split=0.1) \n",
    "score = model.evaluate(x_test, y_test) # [loss, acc]\n",
    "\n",
    "print('loss: ', score[0])\n",
    "print('acc: ', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model 저장\n",
    "\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "    \n",
    "# weight 저장\n",
    "\n",
    "model.save_weights(\"model.h5\")\n",
    "\n",
    "# model 불러오기\n",
    "\n",
    "from keras.models import model_from_json\n",
    "json_file = open(\"model.json\", \"r\")\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "loaded_model.load_weights(\"model.h5\")\n",
    "\n",
    "loaded_model.compile()\n",
    "loaded_model.evalute()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
