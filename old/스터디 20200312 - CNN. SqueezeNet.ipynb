{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\User\\Anaconda3\\envs\\venv\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From C:\\Users\\User\\Anaconda3\\envs\\venv\\lib\\site-packages\\keras-2.3.1-py3.7.egg\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 112, 112, 96) 14208       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 56, 56, 96)   0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 56, 56, 16)   1552        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 56, 56, 16)   0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 56, 56, 64)   1088        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 56, 56, 64)   9280        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 56, 56, 64)   0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 56, 56, 64)   0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 56, 56, 128)  0           activation_2[0][0]               \n",
      "                                                                 activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 56, 56, 128)  0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 56, 56, 16)   2064        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 56, 56, 16)   0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 56, 56, 64)   1088        activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 56, 56, 64)   9280        activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 56, 56, 64)   0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 56, 56, 64)   0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 56, 56, 128)  0           activation_6[0][0]               \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 56, 56, 128)  0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 56, 56, 32)   4128        activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 56, 56, 32)   0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 56, 56, 128)  4224        activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 56, 56, 128)  36992       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 56, 56, 128)  0           conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 56, 56, 128)  0           conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 56, 56, 256)  0           activation_10[0][0]              \n",
      "                                                                 activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 56, 56, 256)  0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 28, 28, 256)  0           activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 28, 28, 32)   8224        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 28, 28, 32)   0           conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 28, 28, 128)  4224        activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 28, 28, 128)  36992       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 28, 28, 128)  0           conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 28, 28, 128)  0           conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 28, 28, 256)  0           activation_14[0][0]              \n",
      "                                                                 activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 28, 28, 256)  0           concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 28, 28, 48)   12336       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 28, 28, 48)   0           conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 28, 28, 192)  9408        activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 28, 28, 192)  83136       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 28, 28, 192)  0           conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 28, 28, 192)  0           conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 28, 28, 384)  0           activation_18[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 28, 28, 384)  0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 28, 28, 48)   18480       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 28, 28, 48)   0           conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 28, 28, 192)  9408        activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 28, 28, 192)  83136       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 28, 28, 192)  0           conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 28, 28, 192)  0           conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 28, 28, 384)  0           activation_22[0][0]              \n",
      "                                                                 activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 28, 28, 384)  0           concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 28, 28, 64)   24640       activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 28, 28, 64)   0           conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 28, 28, 256)  16640       activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 28, 28, 256)  147712      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 28, 28, 256)  0           conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 28, 28, 256)  0           conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 28, 28, 512)  0           activation_26[0][0]              \n",
      "                                                                 activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 28, 28, 512)  0           concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 14, 14, 512)  0           activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 14, 14, 64)   32832       max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 14, 14, 64)   0           conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 14, 14, 256)  16640       activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 14, 14, 256)  147712      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 14, 14, 256)  0           conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 14, 14, 256)  0           conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 14, 14, 512)  0           activation_30[0][0]              \n",
      "                                                                 activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 14, 14, 512)  0           concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 14, 14, 512)  0           activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 14, 14, 1000) 513000      dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 1000)         0           conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 1000)         0           global_average_pooling2d_1[0][0] \n",
      "==================================================================================================\n",
      "Total params: 1,248,424\n",
      "Trainable params: 1,248,424\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 케라스\n",
    "\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Dropout, Flatten, Dense, GlobalAveragePooling2D, concatenate, Activation\n",
    "from keras.models import Model\n",
    "\n",
    "def fire(pre_layer, sq, ex):\n",
    "    squeeze = Conv2D(sq, kernel_size=(1,1), padding='same')(pre_layer)\n",
    "    squeeze = Activation('relu')(squeeze)\n",
    "    expand_11 = Conv2D(ex, kernel_size=(1,1), padding='same')(squeeze)\n",
    "    expand_11 = Activation('relu')(expand_11)\n",
    "    expand_33 = Conv2D(ex, kernel_size=(3,3), padding='same')(squeeze)\n",
    "    expand_33 = Activation('relu')(expand_33)\n",
    "    x = concatenate([expand_11, expand_33])\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "inputs = Input(shape=(224, 224, 3))\n",
    "\n",
    "x = Conv2D(96, kernel_size=(7,7), strides=2, padding='same')(inputs)\n",
    "x = MaxPooling2D(pool_size=(3,3), strides=2, padding='same')(x)\n",
    "x = fire(x, 16, 64)\n",
    "x = fire(x, 16, 64)\n",
    "x = fire(x, 32, 128)\n",
    "x = MaxPooling2D(pool_size=(3,3), strides=2, padding='same')(x)\n",
    "x = fire(x, 32, 128)\n",
    "x = fire(x, 48, 192)\n",
    "x = fire(x, 48, 192)\n",
    "x = fire(x, 64, 256)\n",
    "x = MaxPooling2D(pool_size=(3,3), strides=2, padding='same')(x)\n",
    "x = fire(x, 64, 256)\n",
    "x = Dropout((0.5))(x)\n",
    "x = Conv2D(1000, kernel_size=(1,1), padding='same')(x)\n",
    "x = GlobalAveragePooling2D()(x) # AvgPool이라고 쓰여져 있지만 Dense 대신에 쓰였으므로 GlobalAvgPool 씀\n",
    "x = Activation('softmax')(x) # 최근엔 classifier로 FC(Dense)대신 GAP 많이 쓴다 - 파라미터 수 줄이고 과적합 피함\n",
    "\n",
    "outputs = x\n",
    "\n",
    "model = Model(inputs, outputs)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 96, 112, 112]          14,208\n",
      "         MaxPool2d-2           [-1, 96, 56, 56]               0\n",
      "            Conv2d-3           [-1, 16, 56, 56]           1,552\n",
      "              ReLU-4           [-1, 16, 56, 56]               0\n",
      "            Conv2d-5           [-1, 64, 56, 56]           1,088\n",
      "              ReLU-6           [-1, 64, 56, 56]               0\n",
      "            Conv2d-7           [-1, 64, 56, 56]           9,280\n",
      "              ReLU-8           [-1, 64, 56, 56]               0\n",
      "       fire_module-9          [-1, 128, 56, 56]               0\n",
      "           Conv2d-10           [-1, 16, 56, 56]           2,064\n",
      "             ReLU-11           [-1, 16, 56, 56]               0\n",
      "           Conv2d-12           [-1, 64, 56, 56]           1,088\n",
      "             ReLU-13           [-1, 64, 56, 56]               0\n",
      "           Conv2d-14           [-1, 64, 56, 56]           9,280\n",
      "             ReLU-15           [-1, 64, 56, 56]               0\n",
      "      fire_module-16          [-1, 128, 56, 56]               0\n",
      "           Conv2d-17           [-1, 32, 56, 56]           4,128\n",
      "             ReLU-18           [-1, 32, 56, 56]               0\n",
      "           Conv2d-19          [-1, 128, 56, 56]           4,224\n",
      "             ReLU-20          [-1, 128, 56, 56]               0\n",
      "           Conv2d-21          [-1, 128, 56, 56]          36,992\n",
      "             ReLU-22          [-1, 128, 56, 56]               0\n",
      "      fire_module-23          [-1, 256, 56, 56]               0\n",
      "        MaxPool2d-24          [-1, 256, 28, 28]               0\n",
      "           Conv2d-25           [-1, 32, 28, 28]           8,224\n",
      "             ReLU-26           [-1, 32, 28, 28]               0\n",
      "           Conv2d-27          [-1, 128, 28, 28]           4,224\n",
      "             ReLU-28          [-1, 128, 28, 28]               0\n",
      "           Conv2d-29          [-1, 128, 28, 28]          36,992\n",
      "             ReLU-30          [-1, 128, 28, 28]               0\n",
      "      fire_module-31          [-1, 256, 28, 28]               0\n",
      "           Conv2d-32           [-1, 48, 28, 28]          12,336\n",
      "             ReLU-33           [-1, 48, 28, 28]               0\n",
      "           Conv2d-34          [-1, 192, 28, 28]           9,408\n",
      "             ReLU-35          [-1, 192, 28, 28]               0\n",
      "           Conv2d-36          [-1, 192, 28, 28]          83,136\n",
      "             ReLU-37          [-1, 192, 28, 28]               0\n",
      "      fire_module-38          [-1, 384, 28, 28]               0\n",
      "           Conv2d-39           [-1, 48, 28, 28]          18,480\n",
      "             ReLU-40           [-1, 48, 28, 28]               0\n",
      "           Conv2d-41          [-1, 192, 28, 28]           9,408\n",
      "             ReLU-42          [-1, 192, 28, 28]               0\n",
      "           Conv2d-43          [-1, 192, 28, 28]          83,136\n",
      "             ReLU-44          [-1, 192, 28, 28]               0\n",
      "      fire_module-45          [-1, 384, 28, 28]               0\n",
      "           Conv2d-46           [-1, 64, 28, 28]          24,640\n",
      "             ReLU-47           [-1, 64, 28, 28]               0\n",
      "           Conv2d-48          [-1, 256, 28, 28]          16,640\n",
      "             ReLU-49          [-1, 256, 28, 28]               0\n",
      "           Conv2d-50          [-1, 256, 28, 28]         147,712\n",
      "             ReLU-51          [-1, 256, 28, 28]               0\n",
      "      fire_module-52          [-1, 512, 28, 28]               0\n",
      "        MaxPool2d-53          [-1, 512, 14, 14]               0\n",
      "           Conv2d-54           [-1, 64, 14, 14]          32,832\n",
      "             ReLU-55           [-1, 64, 14, 14]               0\n",
      "           Conv2d-56          [-1, 256, 14, 14]          16,640\n",
      "             ReLU-57          [-1, 256, 14, 14]               0\n",
      "           Conv2d-58          [-1, 256, 14, 14]         147,712\n",
      "             ReLU-59          [-1, 256, 14, 14]               0\n",
      "      fire_module-60          [-1, 512, 14, 14]               0\n",
      "          Dropout-61          [-1, 512, 14, 14]               0\n",
      "           Conv2d-62         [-1, 1000, 14, 14]         513,000\n",
      "AdaptiveAvgPool2d-63           [-1, 1000, 1, 1]               0\n",
      "             View-64                 [-1, 1000]               0\n",
      "================================================================\n",
      "Total params: 1,248,424\n",
      "Trainable params: 1,248,424\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 88.22\n",
      "Params size (MB): 4.76\n",
      "Estimated Total Size (MB): 93.55\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class fire_module(nn.Module):\n",
    "    def __init__(self, in_ch,  sq, ex):\n",
    "        super(fire_module, self).__init__()\n",
    "        layers = []\n",
    "        layers += [nn.Conv2d(in_ch, sq, kernel_size=1),\n",
    "                   nn.ReLU(True)]\n",
    "        expand1 = []\n",
    "        expand1 += [nn.Conv2d(sq, ex, kernel_size=1), # in_channel: sq, out_channel: ex\n",
    "                    nn.ReLU(True)]\n",
    "        expand2 = []\n",
    "        expand2 += [nn.Conv2d(sq, ex, kernel_size=3, padding=1),\n",
    "                    nn.ReLU(True)]\n",
    "\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "        self.expand1 = nn.Sequential(*expand1)\n",
    "        self.expand2 = nn.Sequential(*expand2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        ex1 = self.expand1(x)\n",
    "        ex2 = self.expand2(x)\n",
    "        return torch.cat((ex1, ex2), 1)\n",
    "\n",
    "class SqeezeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SqeezeNet, self).__init__()\n",
    "        layers = []\n",
    "        layers += [nn.Conv2d(in_channels=3, out_channels=96, kernel_size=7, stride=2, padding=3),\n",
    "                   nn.MaxPool2d(3, 2, 1), # filter_size, stride, padding\n",
    "                   fire_module(96, 16, 64),\n",
    "                   fire_module(128, 16, 64),\n",
    "                   fire_module(128, 32, 128),\n",
    "                   nn.MaxPool2d(3, 2, 1),\n",
    "                   fire_module(256, 32, 128),\n",
    "                   fire_module(256, 48, 192),\n",
    "                   fire_module(384, 48, 192),\n",
    "                   fire_module(384, 64, 256),\n",
    "                   nn.MaxPool2d(3, 2, 1),\n",
    "                   fire_module(512, 64, 256),\n",
    "                   nn.Dropout(0.5),\n",
    "                   nn.Conv2d(512, 1000, 1),\n",
    "                   nn.AdaptiveAvgPool2d((1,1)), # batch * 1000 * 1 * 1\n",
    "                   View(-1)] # batch * 1000 * 1 * 1 는 우리가 보기에 1차원이지만 컴퓨터가 보기엔 4차원이므로 그걸 해결하기 위함\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "class View(nn.Module):\n",
    "\n",
    "    def __init__(self, *shape):\n",
    "        super(View, self).__init__()\n",
    "        self.shape = shape\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.view(x.shape[0], *self.shape)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    from torchsummary import summary\n",
    "    model = SqeezeNet()\n",
    "    summary(model, (3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
