{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파이토치 (이번엔 파이토치에 대해서 mnist 훈련 X, 모델만 짰음)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "import argparse\n",
    "import time\n",
    "from copy import deepcopy\n",
    "import matplotlib.pyplot as plt\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 14, 14]             288\n",
      "       BatchNorm2d-2           [-1, 32, 14, 14]              64\n",
      "              ReLU-3           [-1, 32, 14, 14]               0\n",
      "            Conv2d-4           [-1, 64, 14, 14]          18,432\n",
      "       BatchNorm2d-5           [-1, 64, 14, 14]             128\n",
      "              ReLU-6           [-1, 64, 14, 14]               0\n",
      "            Conv2d-7           [-1, 64, 14, 14]             576\n",
      "            Conv2d-8          [-1, 128, 14, 14]           8,192\n",
      "       BatchNorm2d-9          [-1, 128, 14, 14]             256\n",
      "          Sepconv-10          [-1, 128, 14, 14]               0\n",
      "             ReLU-11          [-1, 128, 14, 14]               0\n",
      "           Conv2d-12          [-1, 128, 14, 14]           1,152\n",
      "           Conv2d-13          [-1, 128, 14, 14]          16,384\n",
      "      BatchNorm2d-14          [-1, 128, 14, 14]             256\n",
      "          Sepconv-15          [-1, 128, 14, 14]               0\n",
      "        MaxPool2d-16            [-1, 128, 7, 7]               0\n",
      "           Conv2d-17            [-1, 128, 7, 7]           8,192\n",
      "      BatchNorm2d-18            [-1, 128, 7, 7]             256\n",
      "             ReLU-19            [-1, 128, 7, 7]               0\n",
      "           Conv2d-20            [-1, 128, 7, 7]           1,152\n",
      "           Conv2d-21            [-1, 256, 7, 7]          32,768\n",
      "      BatchNorm2d-22            [-1, 256, 7, 7]             512\n",
      "          Sepconv-23            [-1, 256, 7, 7]               0\n",
      "             ReLU-24            [-1, 256, 7, 7]               0\n",
      "           Conv2d-25            [-1, 256, 7, 7]           2,304\n",
      "           Conv2d-26            [-1, 256, 7, 7]          65,536\n",
      "      BatchNorm2d-27            [-1, 256, 7, 7]             512\n",
      "          Sepconv-28            [-1, 256, 7, 7]               0\n",
      "        MaxPool2d-29            [-1, 256, 4, 4]               0\n",
      "           Conv2d-30            [-1, 256, 4, 4]          32,768\n",
      "      BatchNorm2d-31            [-1, 256, 4, 4]             512\n",
      "             ReLU-32            [-1, 256, 4, 4]               0\n",
      "           Conv2d-33            [-1, 256, 4, 4]           2,304\n",
      "           Conv2d-34            [-1, 728, 4, 4]         186,368\n",
      "      BatchNorm2d-35            [-1, 728, 4, 4]           1,456\n",
      "          Sepconv-36            [-1, 728, 4, 4]               0\n",
      "             ReLU-37            [-1, 728, 4, 4]               0\n",
      "           Conv2d-38            [-1, 728, 4, 4]           6,552\n",
      "           Conv2d-39            [-1, 728, 4, 4]         529,984\n",
      "      BatchNorm2d-40            [-1, 728, 4, 4]           1,456\n",
      "          Sepconv-41            [-1, 728, 4, 4]               0\n",
      "        MaxPool2d-42            [-1, 728, 2, 2]               0\n",
      "           Conv2d-43            [-1, 728, 2, 2]         186,368\n",
      "      BatchNorm2d-44            [-1, 728, 2, 2]           1,456\n",
      "       Entry_flow-45            [-1, 728, 2, 2]               0\n",
      "             ReLU-46            [-1, 728, 2, 2]               0\n",
      "           Conv2d-47            [-1, 728, 2, 2]           6,552\n",
      "           Conv2d-48            [-1, 728, 2, 2]         529,984\n",
      "      BatchNorm2d-49            [-1, 728, 2, 2]           1,456\n",
      "          Sepconv-50            [-1, 728, 2, 2]               0\n",
      "             ReLU-51            [-1, 728, 2, 2]               0\n",
      "           Conv2d-52            [-1, 728, 2, 2]           6,552\n",
      "           Conv2d-53            [-1, 728, 2, 2]         529,984\n",
      "      BatchNorm2d-54            [-1, 728, 2, 2]           1,456\n",
      "          Sepconv-55            [-1, 728, 2, 2]               0\n",
      "             ReLU-56            [-1, 728, 2, 2]               0\n",
      "           Conv2d-57            [-1, 728, 2, 2]           6,552\n",
      "           Conv2d-58            [-1, 728, 2, 2]         529,984\n",
      "      BatchNorm2d-59            [-1, 728, 2, 2]           1,456\n",
      "          Sepconv-60            [-1, 728, 2, 2]               0\n",
      "      Middle_flow-61            [-1, 728, 2, 2]               0\n",
      "             ReLU-62            [-1, 728, 2, 2]               0\n",
      "           Conv2d-63            [-1, 728, 2, 2]           6,552\n",
      "           Conv2d-64            [-1, 728, 2, 2]         529,984\n",
      "      BatchNorm2d-65            [-1, 728, 2, 2]           1,456\n",
      "          Sepconv-66            [-1, 728, 2, 2]               0\n",
      "             ReLU-67            [-1, 728, 2, 2]               0\n",
      "           Conv2d-68            [-1, 728, 2, 2]           6,552\n",
      "           Conv2d-69            [-1, 728, 2, 2]         529,984\n",
      "      BatchNorm2d-70            [-1, 728, 2, 2]           1,456\n",
      "          Sepconv-71            [-1, 728, 2, 2]               0\n",
      "             ReLU-72            [-1, 728, 2, 2]               0\n",
      "           Conv2d-73            [-1, 728, 2, 2]           6,552\n",
      "           Conv2d-74            [-1, 728, 2, 2]         529,984\n",
      "      BatchNorm2d-75            [-1, 728, 2, 2]           1,456\n",
      "          Sepconv-76            [-1, 728, 2, 2]               0\n",
      "      Middle_flow-77            [-1, 728, 2, 2]               0\n",
      "             ReLU-78            [-1, 728, 2, 2]               0\n",
      "           Conv2d-79            [-1, 728, 2, 2]           6,552\n",
      "           Conv2d-80            [-1, 728, 2, 2]         529,984\n",
      "      BatchNorm2d-81            [-1, 728, 2, 2]           1,456\n",
      "          Sepconv-82            [-1, 728, 2, 2]               0\n",
      "             ReLU-83            [-1, 728, 2, 2]               0\n",
      "           Conv2d-84            [-1, 728, 2, 2]           6,552\n",
      "           Conv2d-85            [-1, 728, 2, 2]         529,984\n",
      "      BatchNorm2d-86            [-1, 728, 2, 2]           1,456\n",
      "          Sepconv-87            [-1, 728, 2, 2]               0\n",
      "             ReLU-88            [-1, 728, 2, 2]               0\n",
      "           Conv2d-89            [-1, 728, 2, 2]           6,552\n",
      "           Conv2d-90            [-1, 728, 2, 2]         529,984\n",
      "      BatchNorm2d-91            [-1, 728, 2, 2]           1,456\n",
      "          Sepconv-92            [-1, 728, 2, 2]               0\n",
      "      Middle_flow-93            [-1, 728, 2, 2]               0\n",
      "             ReLU-94            [-1, 728, 2, 2]               0\n",
      "           Conv2d-95            [-1, 728, 2, 2]           6,552\n",
      "           Conv2d-96            [-1, 728, 2, 2]         529,984\n",
      "      BatchNorm2d-97            [-1, 728, 2, 2]           1,456\n",
      "          Sepconv-98            [-1, 728, 2, 2]               0\n",
      "             ReLU-99            [-1, 728, 2, 2]               0\n",
      "          Conv2d-100            [-1, 728, 2, 2]           6,552\n",
      "          Conv2d-101            [-1, 728, 2, 2]         529,984\n",
      "     BatchNorm2d-102            [-1, 728, 2, 2]           1,456\n",
      "         Sepconv-103            [-1, 728, 2, 2]               0\n",
      "            ReLU-104            [-1, 728, 2, 2]               0\n",
      "          Conv2d-105            [-1, 728, 2, 2]           6,552\n",
      "          Conv2d-106            [-1, 728, 2, 2]         529,984\n",
      "     BatchNorm2d-107            [-1, 728, 2, 2]           1,456\n",
      "         Sepconv-108            [-1, 728, 2, 2]               0\n",
      "     Middle_flow-109            [-1, 728, 2, 2]               0\n",
      "            ReLU-110            [-1, 728, 2, 2]               0\n",
      "          Conv2d-111            [-1, 728, 2, 2]           6,552\n",
      "          Conv2d-112            [-1, 728, 2, 2]         529,984\n",
      "     BatchNorm2d-113            [-1, 728, 2, 2]           1,456\n",
      "         Sepconv-114            [-1, 728, 2, 2]               0\n",
      "            ReLU-115            [-1, 728, 2, 2]               0\n",
      "          Conv2d-116            [-1, 728, 2, 2]           6,552\n",
      "          Conv2d-117            [-1, 728, 2, 2]         529,984\n",
      "     BatchNorm2d-118            [-1, 728, 2, 2]           1,456\n",
      "         Sepconv-119            [-1, 728, 2, 2]               0\n",
      "            ReLU-120            [-1, 728, 2, 2]               0\n",
      "          Conv2d-121            [-1, 728, 2, 2]           6,552\n",
      "          Conv2d-122            [-1, 728, 2, 2]         529,984\n",
      "     BatchNorm2d-123            [-1, 728, 2, 2]           1,456\n",
      "         Sepconv-124            [-1, 728, 2, 2]               0\n",
      "     Middle_flow-125            [-1, 728, 2, 2]               0\n",
      "            ReLU-126            [-1, 728, 2, 2]               0\n",
      "          Conv2d-127            [-1, 728, 2, 2]           6,552\n",
      "          Conv2d-128            [-1, 728, 2, 2]         529,984\n",
      "     BatchNorm2d-129            [-1, 728, 2, 2]           1,456\n",
      "         Sepconv-130            [-1, 728, 2, 2]               0\n",
      "            ReLU-131            [-1, 728, 2, 2]               0\n",
      "          Conv2d-132            [-1, 728, 2, 2]           6,552\n",
      "          Conv2d-133            [-1, 728, 2, 2]         529,984\n",
      "     BatchNorm2d-134            [-1, 728, 2, 2]           1,456\n",
      "         Sepconv-135            [-1, 728, 2, 2]               0\n",
      "            ReLU-136            [-1, 728, 2, 2]               0\n",
      "          Conv2d-137            [-1, 728, 2, 2]           6,552\n",
      "          Conv2d-138            [-1, 728, 2, 2]         529,984\n",
      "     BatchNorm2d-139            [-1, 728, 2, 2]           1,456\n",
      "         Sepconv-140            [-1, 728, 2, 2]               0\n",
      "     Middle_flow-141            [-1, 728, 2, 2]               0\n",
      "            ReLU-142            [-1, 728, 2, 2]               0\n",
      "          Conv2d-143            [-1, 728, 2, 2]           6,552\n",
      "          Conv2d-144            [-1, 728, 2, 2]         529,984\n",
      "     BatchNorm2d-145            [-1, 728, 2, 2]           1,456\n",
      "         Sepconv-146            [-1, 728, 2, 2]               0\n",
      "            ReLU-147            [-1, 728, 2, 2]               0\n",
      "          Conv2d-148            [-1, 728, 2, 2]           6,552\n",
      "          Conv2d-149            [-1, 728, 2, 2]         529,984\n",
      "     BatchNorm2d-150            [-1, 728, 2, 2]           1,456\n",
      "         Sepconv-151            [-1, 728, 2, 2]               0\n",
      "            ReLU-152            [-1, 728, 2, 2]               0\n",
      "          Conv2d-153            [-1, 728, 2, 2]           6,552\n",
      "          Conv2d-154            [-1, 728, 2, 2]         529,984\n",
      "     BatchNorm2d-155            [-1, 728, 2, 2]           1,456\n",
      "         Sepconv-156            [-1, 728, 2, 2]               0\n",
      "     Middle_flow-157            [-1, 728, 2, 2]               0\n",
      "            ReLU-158            [-1, 728, 2, 2]               0\n",
      "          Conv2d-159            [-1, 728, 2, 2]           6,552\n",
      "          Conv2d-160            [-1, 728, 2, 2]         529,984\n",
      "     BatchNorm2d-161            [-1, 728, 2, 2]           1,456\n",
      "         Sepconv-162            [-1, 728, 2, 2]               0\n",
      "            ReLU-163            [-1, 728, 2, 2]               0\n",
      "          Conv2d-164            [-1, 728, 2, 2]           6,552\n",
      "          Conv2d-165            [-1, 728, 2, 2]         529,984\n",
      "     BatchNorm2d-166            [-1, 728, 2, 2]           1,456\n",
      "         Sepconv-167            [-1, 728, 2, 2]               0\n",
      "            ReLU-168            [-1, 728, 2, 2]               0\n",
      "          Conv2d-169            [-1, 728, 2, 2]           6,552\n",
      "          Conv2d-170            [-1, 728, 2, 2]         529,984\n",
      "     BatchNorm2d-171            [-1, 728, 2, 2]           1,456\n",
      "         Sepconv-172            [-1, 728, 2, 2]               0\n",
      "     Middle_flow-173            [-1, 728, 2, 2]               0\n",
      "            ReLU-174            [-1, 728, 2, 2]               0\n",
      "          Conv2d-175            [-1, 728, 2, 2]           6,552\n",
      "          Conv2d-176            [-1, 728, 2, 2]         529,984\n",
      "     BatchNorm2d-177            [-1, 728, 2, 2]           1,456\n",
      "         Sepconv-178            [-1, 728, 2, 2]               0\n",
      "            ReLU-179            [-1, 728, 2, 2]               0\n",
      "          Conv2d-180            [-1, 728, 2, 2]           6,552\n",
      "          Conv2d-181           [-1, 1024, 2, 2]         745,472\n",
      "     BatchNorm2d-182           [-1, 1024, 2, 2]           2,048\n",
      "         Sepconv-183           [-1, 1024, 2, 2]               0\n",
      "       MaxPool2d-184           [-1, 1024, 1, 1]               0\n",
      "          Conv2d-185           [-1, 1024, 1, 1]         745,472\n",
      "     BatchNorm2d-186           [-1, 1024, 1, 1]           2,048\n",
      "          Conv2d-187           [-1, 1024, 1, 1]           9,216\n",
      "          Conv2d-188           [-1, 1536, 1, 1]       1,572,864\n",
      "     BatchNorm2d-189           [-1, 1536, 1, 1]           3,072\n",
      "         Sepconv-190           [-1, 1536, 1, 1]               0\n",
      "            ReLU-191           [-1, 1536, 1, 1]               0\n",
      "          Conv2d-192           [-1, 1536, 1, 1]          13,824\n",
      "          Conv2d-193           [-1, 2048, 1, 1]       3,145,728\n",
      "     BatchNorm2d-194           [-1, 2048, 1, 1]           4,096\n",
      "         Sepconv-195           [-1, 2048, 1, 1]               0\n",
      "            ReLU-196           [-1, 2048, 1, 1]               0\n",
      "AdaptiveAvgPool2d-197           [-1, 2048, 1, 1]               0\n",
      "            View-198                 [-1, 2048]               0\n",
      "          Linear-199                 [-1, 1000]       2,049,000\n",
      "       Exit_flow-200                 [-1, 1000]               0\n",
      "================================================================\n",
      "Total params: 22,855,376\n",
      "Trainable params: 22,855,376\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 7.31\n",
      "Params size (MB): 87.19\n",
      "Estimated Total Size (MB): 94.50\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "class View(nn.Module):\n",
    "\n",
    "    def __init__(self, *shape):\n",
    "        super(View, self).__init__()\n",
    "        self.shape = shape\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.view(x.shape[0], *self.shape) # x.shape == (batch_size, channel, width, height) \n",
    "    \n",
    "    # x = batch_size * channel * width * height(나가는 패러미터의 갯수)\n",
    "\n",
    "class Sepconv(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channel, outchannel):\n",
    "        super(Sepconv, self).__init__()\n",
    "        sepconv = []\n",
    "        # spatial 연산할 땐 in out 채널 갯수 똑같아야 됨. 이미지 사이즈는 일단 그대로 (공간 연산으로 줄일수는 있음)\n",
    "        # groups는 in 채널 갯수만큼 그룹을 지어서 하나하나씩만 계산하도록 한다.\n",
    "        sepconv += [nn.Conv2d(in_channels=in_channel, out_channels=in_channel, kernel_size=3, stride=1, padding=1, groups=in_channel, bias=False),\n",
    "                    nn.Conv2d(in_channels=in_channel, out_channels=outchannel, kernel_size=1, stride=1, bias=False),\n",
    "                    nn.BatchNorm2d(num_features=outchannel)]\n",
    "\n",
    "        self.layers = nn.Sequential(*sepconv)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "class Entry_flow(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Entry_flow, self).__init__()\n",
    "\n",
    "        layer1 = []\n",
    "        layer1 += [nn.Conv2d(1, 32, kernel_size=3, stride=2, padding=1, bias=False), # mnist이므로 in 채널 1개\n",
    "                   nn.BatchNorm2d(32),\n",
    "                   nn.ReLU(inplace=True),\n",
    "                   nn.Conv2d(32, 64, kernel_size=3, padding=1, bias=False),\n",
    "                   nn.BatchNorm2d(64),\n",
    "                   nn.ReLU(True)]\n",
    "        layer2 = []\n",
    "        layer2 += [Sepconv(64, 128), # Sepconv자체에 BN 들어가므로 Sepconv뒤에 굳이 BN 안넣음\n",
    "                   nn.ReLU(True),\n",
    "                   Sepconv(128, 128),\n",
    "                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1)]\n",
    "        layer3 = []\n",
    "        layer3 += [nn.ReLU(True),\n",
    "                   Sepconv(128, 256),\n",
    "                   nn.ReLU(True),\n",
    "                   Sepconv(256, 256),\n",
    "                   nn.MaxPool2d(3, 2, padding=1)]\n",
    "        layer4 = []\n",
    "        layer4 += [nn.ReLU(True),\n",
    "                   Sepconv(256, 728),\n",
    "                   nn.ReLU(True),\n",
    "                   Sepconv(728, 728),\n",
    "                   nn.MaxPool2d(3, 2, padding=1)]\n",
    "\n",
    "        self.layer1 = nn.Sequential(*layer1)\n",
    "        self.layer2 = nn.Sequential(*layer2)\n",
    "        self.layer3 = nn.Sequential(*layer3)\n",
    "        self.layer4 = nn.Sequential(*layer4)\n",
    "        # +를 해주려면 모든 텐서의 dimension이 같아야.\n",
    "        self.skip_con1 = nn.Sequential(*[nn.Conv2d(64, 128, kernel_size=1, stride=2, bias=False), # layer1에 대한 것\n",
    "                                         nn.BatchNorm2d(128)])\n",
    "        self.skip_con2 = nn.Sequential(*[nn.Conv2d(128, 256, 1, 2, bias=False), # layer2에 대한 것\n",
    "                                         nn.BatchNorm2d(256)])\n",
    "        self.skip_con3 = nn.Sequential(*[nn.Conv2d(256, 728, 1, 2, bias=False), # layer3에 대한 것\n",
    "                                         nn.BatchNorm2d(728)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.layer1(x)\n",
    "        x2 = self.layer2(x1)\n",
    "        skip = self.skip_con1(x1)\n",
    "        x2 = x2+skip\n",
    "        x3 = self.layer3(x2)\n",
    "        skip = self.skip_con2(x2)\n",
    "        x3 = x3+skip\n",
    "        x4 = self.layer4(x3)\n",
    "        skip = self.skip_con3(x3)\n",
    "        return x4+skip\n",
    "\n",
    "class Middle_flow(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Middle_flow, self).__init__()\n",
    "\n",
    "        layer = []\n",
    "        layer += [nn.ReLU(True),\n",
    "                  Sepconv(728, 728),\n",
    "                  nn.ReLU(True),\n",
    "                  Sepconv(728, 728),\n",
    "                  nn.ReLU(True),\n",
    "                  Sepconv(728, 728)]\n",
    "\n",
    "        self.layers = nn.Sequential(*layer)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layers(x)\n",
    "        return out+x\n",
    "\n",
    "class Exit_flow(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Exit_flow, self).__init__()\n",
    "\n",
    "        layer1 = []\n",
    "        layer1 += [nn.ReLU(True),\n",
    "                   Sepconv(728, 728),\n",
    "                   nn.ReLU(True),\n",
    "                   Sepconv(728, 1024),\n",
    "                   nn.MaxPool2d(3, 2, padding=1)]\n",
    "\n",
    "        layer2 = []\n",
    "        layer2 += [Sepconv(1024, 1536),\n",
    "                   nn.ReLU(True),\n",
    "                   Sepconv(1536, 2048),\n",
    "                   nn.ReLU(True),\n",
    "                   nn.AdaptiveAvgPool2d((1,1)),\n",
    "                   View(-1), # flatten 과정\n",
    "                   nn.Linear(2048, 1000)]\n",
    "\n",
    "        self.layer1 = nn.Sequential(*layer1)\n",
    "        self.layer2 = nn.Sequential(*layer2)\n",
    "        self.skip_con = nn.Conv2d(in_channels=728, out_channels=1024, kernel_size=1, stride=2, bias=False)\n",
    "        self.bn = nn.BatchNorm2d(1024)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        out1 = self.layer1(x)\n",
    "        skip = self.skip_con(x)\n",
    "        skip = self.bn(skip)\n",
    "        output = self.layer2(out1+skip)\n",
    "        return output\n",
    "    \n",
    "class Xception(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Xception, self).__init__()\n",
    "\n",
    "        layers = []\n",
    "        layers += [Entry_flow(),\n",
    "                   Middle_flow(),\n",
    "                   Middle_flow(),\n",
    "                   Middle_flow(),\n",
    "                   Middle_flow(),\n",
    "                   Middle_flow(),\n",
    "                   Middle_flow(),\n",
    "                   Middle_flow(),\n",
    "                   Middle_flow(),\n",
    "                   Exit_flow()]\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y_pred = self.layers(x)\n",
    "        return y_pred\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    from torchsummary import summary\n",
    "    model = Xception()\n",
    "    summary(model, (1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 28, 28, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 14, 14, 32)   288         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 14, 14, 32)   128         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 14, 14, 32)   0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 14, 14, 64)   18432       activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 14, 14, 64)   256         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 14, 14, 64)   0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 14, 14, 64)   0           activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_69 (SeparableC (None, 14, 14, 128)  8768        activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 14, 14, 128)  512         separable_conv2d_69[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 14, 14, 128)  0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_70 (SeparableC (None, 14, 14, 128)  17536       activation_76[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 14, 14, 128)  512         separable_conv2d_70[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 7, 7, 128)    8192        activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2D)  (None, 7, 7, 128)    0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 7, 7, 128)    512         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_25 (Add)                    (None, 7, 7, 128)    0           max_pooling2d_9[0][0]            \n",
      "                                                                 batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 7, 7, 128)    0           add_25[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_71 (SeparableC (None, 7, 7, 256)    33920       activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 7, 7, 256)    1024        separable_conv2d_71[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 7, 7, 256)    0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_72 (SeparableC (None, 7, 7, 256)    67840       activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 7, 7, 256)    1024        separable_conv2d_72[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 4, 4, 256)    32768       add_25[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling2D) (None, 4, 4, 256)    0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 4, 4, 256)    1024        conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_26 (Add)                    (None, 4, 4, 256)    0           max_pooling2d_10[0][0]           \n",
      "                                                                 batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 4, 4, 256)    0           add_26[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_73 (SeparableC (None, 4, 4, 728)    188672      activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 4, 4, 728)    2912        separable_conv2d_73[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 4, 4, 728)    0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_74 (SeparableC (None, 4, 4, 728)    536536      activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 4, 4, 728)    2912        separable_conv2d_74[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 2, 2, 728)    186368      add_26[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling2D) (None, 2, 2, 728)    0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 2, 2, 728)    2912        conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_27 (Add)                    (None, 2, 2, 728)    0           max_pooling2d_11[0][0]           \n",
      "                                                                 batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 2, 2, 728)    0           add_27[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_75 (SeparableC (None, 2, 2, 728)    536536      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 2, 2, 728)    2912        separable_conv2d_75[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 2, 2, 728)    0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_76 (SeparableC (None, 2, 2, 728)    536536      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 2, 2, 728)    2912        separable_conv2d_76[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 2, 2, 728)    0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_77 (SeparableC (None, 2, 2, 728)    536536      activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 2, 2, 728)    2912        separable_conv2d_77[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_28 (Add)                    (None, 2, 2, 728)    0           batch_normalization_94[0][0]     \n",
      "                                                                 add_27[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 2, 2, 728)    0           add_28[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_78 (SeparableC (None, 2, 2, 728)    536536      activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNo (None, 2, 2, 728)    2912        separable_conv2d_78[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 2, 2, 728)    0           batch_normalization_95[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_79 (SeparableC (None, 2, 2, 728)    536536      activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNo (None, 2, 2, 728)    2912        separable_conv2d_79[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 2, 2, 728)    0           batch_normalization_96[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_80 (SeparableC (None, 2, 2, 728)    536536      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNo (None, 2, 2, 728)    2912        separable_conv2d_80[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_29 (Add)                    (None, 2, 2, 728)    0           batch_normalization_97[0][0]     \n",
      "                                                                 add_28[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 2, 2, 728)    0           add_29[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_81 (SeparableC (None, 2, 2, 728)    536536      activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNo (None, 2, 2, 728)    2912        separable_conv2d_81[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 2, 2, 728)    0           batch_normalization_98[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_82 (SeparableC (None, 2, 2, 728)    536536      activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_99 (BatchNo (None, 2, 2, 728)    2912        separable_conv2d_82[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 2, 2, 728)    0           batch_normalization_99[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_83 (SeparableC (None, 2, 2, 728)    536536      activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_100 (BatchN (None, 2, 2, 728)    2912        separable_conv2d_83[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_30 (Add)                    (None, 2, 2, 728)    0           batch_normalization_100[0][0]    \n",
      "                                                                 add_29[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 2, 2, 728)    0           add_30[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_84 (SeparableC (None, 2, 2, 728)    536536      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_101 (BatchN (None, 2, 2, 728)    2912        separable_conv2d_84[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 2, 2, 728)    0           batch_normalization_101[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_85 (SeparableC (None, 2, 2, 728)    536536      activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_102 (BatchN (None, 2, 2, 728)    2912        separable_conv2d_85[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 2, 2, 728)    0           batch_normalization_102[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_86 (SeparableC (None, 2, 2, 728)    536536      activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_103 (BatchN (None, 2, 2, 728)    2912        separable_conv2d_86[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_31 (Add)                    (None, 2, 2, 728)    0           batch_normalization_103[0][0]    \n",
      "                                                                 add_30[0][0]                     \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activation_93 (Activation)      (None, 2, 2, 728)    0           add_31[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_87 (SeparableC (None, 2, 2, 728)    536536      activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_104 (BatchN (None, 2, 2, 728)    2912        separable_conv2d_87[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, 2, 2, 728)    0           batch_normalization_104[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_88 (SeparableC (None, 2, 2, 728)    536536      activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_105 (BatchN (None, 2, 2, 728)    2912        separable_conv2d_88[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_95 (Activation)      (None, 2, 2, 728)    0           batch_normalization_105[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_89 (SeparableC (None, 2, 2, 728)    536536      activation_95[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_106 (BatchN (None, 2, 2, 728)    2912        separable_conv2d_89[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_32 (Add)                    (None, 2, 2, 728)    0           batch_normalization_106[0][0]    \n",
      "                                                                 add_31[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_96 (Activation)      (None, 2, 2, 728)    0           add_32[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_90 (SeparableC (None, 2, 2, 728)    536536      activation_96[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_107 (BatchN (None, 2, 2, 728)    2912        separable_conv2d_90[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_97 (Activation)      (None, 2, 2, 728)    0           batch_normalization_107[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_91 (SeparableC (None, 2, 2, 728)    536536      activation_97[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_108 (BatchN (None, 2, 2, 728)    2912        separable_conv2d_91[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_98 (Activation)      (None, 2, 2, 728)    0           batch_normalization_108[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_92 (SeparableC (None, 2, 2, 728)    536536      activation_98[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_109 (BatchN (None, 2, 2, 728)    2912        separable_conv2d_92[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_33 (Add)                    (None, 2, 2, 728)    0           batch_normalization_109[0][0]    \n",
      "                                                                 add_32[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_99 (Activation)      (None, 2, 2, 728)    0           add_33[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_93 (SeparableC (None, 2, 2, 728)    536536      activation_99[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_110 (BatchN (None, 2, 2, 728)    2912        separable_conv2d_93[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_100 (Activation)     (None, 2, 2, 728)    0           batch_normalization_110[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_94 (SeparableC (None, 2, 2, 728)    536536      activation_100[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_111 (BatchN (None, 2, 2, 728)    2912        separable_conv2d_94[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_101 (Activation)     (None, 2, 2, 728)    0           batch_normalization_111[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_95 (SeparableC (None, 2, 2, 728)    536536      activation_101[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_112 (BatchN (None, 2, 2, 728)    2912        separable_conv2d_95[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_34 (Add)                    (None, 2, 2, 728)    0           batch_normalization_112[0][0]    \n",
      "                                                                 add_33[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_102 (Activation)     (None, 2, 2, 728)    0           add_34[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_96 (SeparableC (None, 2, 2, 728)    536536      activation_102[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_113 (BatchN (None, 2, 2, 728)    2912        separable_conv2d_96[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_103 (Activation)     (None, 2, 2, 728)    0           batch_normalization_113[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_97 (SeparableC (None, 2, 2, 728)    536536      activation_103[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_114 (BatchN (None, 2, 2, 728)    2912        separable_conv2d_97[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_104 (Activation)     (None, 2, 2, 728)    0           batch_normalization_114[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_98 (SeparableC (None, 2, 2, 728)    536536      activation_104[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_115 (BatchN (None, 2, 2, 728)    2912        separable_conv2d_98[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_35 (Add)                    (None, 2, 2, 728)    0           batch_normalization_115[0][0]    \n",
      "                                                                 add_34[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_105 (Activation)     (None, 2, 2, 728)    0           add_35[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_99 (SeparableC (None, 2, 2, 728)    536536      activation_105[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_116 (BatchN (None, 2, 2, 728)    2912        separable_conv2d_99[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_106 (Activation)     (None, 2, 2, 728)    0           batch_normalization_116[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_100 (Separable (None, 2, 2, 1024)   752024      activation_106[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_117 (BatchN (None, 2, 2, 1024)   4096        separable_conv2d_100[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 1, 1, 1024)   745472      add_35[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling2D) (None, 1, 1, 1024)   0           batch_normalization_117[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_118 (BatchN (None, 1, 1, 1024)   4096        conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_36 (Add)                    (None, 1, 1, 1024)   0           max_pooling2d_12[0][0]           \n",
      "                                                                 batch_normalization_118[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_101 (Separable (None, 1, 1, 1536)   1582080     add_36[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_119 (BatchN (None, 1, 1, 1536)   6144        separable_conv2d_101[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_107 (Activation)     (None, 1, 1, 1536)   0           batch_normalization_119[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_102 (Separable (None, 1, 1, 2048)   3159552     activation_107[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_120 (BatchN (None, 1, 1, 2048)   8192        separable_conv2d_102[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_108 (Activation)     (None, 1, 1, 2048)   0           batch_normalization_120[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_3 (Glo (None, 2048)         0           activation_108[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 10)           20490       global_average_pooling2d_3[0][0] \n",
      "==================================================================================================\n",
      "Total params: 20,881,394\n",
      "Trainable params: 20,826,866\n",
      "Non-trainable params: 54,528\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 케라스\n",
    "\n",
    "# 만약 stride=2이고 padding='same'이면 일단 stride=1인걸로 인식해서, 10*10이미지에 3*3 커널이라면 \n",
    "# 양옆에 padding을 1씩 추가해준 후 막상 stride 재보니까 2인거다. 그렇게 하면 5*5 이미지로 변한다.\n",
    "\n",
    "from keras.layers import Conv2D, MaxPooling2D, SeparableConv2D, BatchNormalization, Dense, GlobalAveragePooling2D, Activation, add, Input\n",
    "from keras.models import Model\n",
    "\n",
    "# Entry Flow (그림 참조)\n",
    "\n",
    "inputs = Input(shape=(28, 28, 1)) # 이미지넷\n",
    "\n",
    "x = Conv2D(32, kernel_size=3, strides=2, padding='same', use_bias=False)(inputs)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Conv2D(64, kernel_size=3, padding='same', use_bias=False)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "# (None, 150, 150, 64)\n",
    "x2 = x\n",
    "\n",
    "# 그림 참조\n",
    "\n",
    "for size in [128, 256, 728]:\n",
    "    \n",
    "    x = Activation('relu')(x)\n",
    "    x = SeparableConv2D(size, kernel_size=3, padding='same', use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = SeparableConv2D(size, kernel_size=3, padding='same', use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D(3, strides=2, padding='same')(x)\n",
    "    \n",
    "    residual_block = Conv2D(size, kernel_size=1, strides=2, padding='same', use_bias=False)(x2)\n",
    "    residual_block = BatchNormalization()(residual_block)\n",
    "    x = add([x, residual_block])\n",
    "    x2 = x # skip connection 위해서 x2로 따로 정의\n",
    "    \n",
    "    # (None, 75, 75, 128) -> (None, 38, 38, 256) -> (None, 19, 19, 728)\n",
    "\n",
    "# Middle flow\n",
    "\n",
    "for _ in range(8):\n",
    "    for _ in range(3):\n",
    "        x = Activation('relu')(x)\n",
    "        x = SeparableConv2D(728, kernel_size=3, padding='same', use_bias=False)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "    x = add([x, x2])\n",
    "    x2 = x\n",
    "    \n",
    "# (None, 19, 19, 728)\n",
    "\n",
    "# Exit flow\n",
    "\n",
    "x = Activation('relu')(x)\n",
    "x = SeparableConv2D(728, kernel_size=3, padding='same', use_bias=False)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = SeparableConv2D(1024, kernel_size=3, padding='same', use_bias=False)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D(3, strides=2, padding='same')(x)\n",
    "\n",
    "residual_block = Conv2D(1024, kernel_size=1, strides=2, padding='same', use_bias=False)(x2)\n",
    "residual_block = BatchNormalization()(residual_block)\n",
    "x = add([x, residual_block])\n",
    "\n",
    "# (None, 10, 10, 1024)\n",
    "\n",
    "x = SeparableConv2D(1536, kernel_size=3, padding='same', use_bias=False)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = SeparableConv2D(2048, kernel_size=3, padding='same', use_bias=False)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "outputs = Dense(10, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs, outputs)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 그림 보기\n",
    "\n",
    "from IPython.display import SVG\n",
    "from keras.utils import model_to_dot\n",
    "\n",
    "SVG(model_to_dot(model, dpi=50).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/1\n"
     ]
    }
   ],
   "source": [
    "# mnist 데이터 준비\n",
    "\n",
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "\n",
    "width = 28\n",
    "height = 28\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(60000, width, height, 1).astype('float32')/255.0\n",
    "x_test = x_test.reshape(10000, width, height, 1).astype('float32')/255.0\n",
    "\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 훈련 \n",
    "\n",
    "model.fit(x_train, y_train, batch_size=1000, epochs=10, verbose=2, validation_split=0.1)\n",
    "score = model.evaluate(x_test, y_test) # [loss, acc]\n",
    "\n",
    "print('loss: ', score[0])\n",
    "print('acc: ', score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
