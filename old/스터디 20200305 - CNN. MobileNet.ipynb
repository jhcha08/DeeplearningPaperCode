{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 32, 112, 112]             864\n",
      "       BatchNorm2d-2         [-1, 32, 112, 112]              64\n",
      "              ReLU-3         [-1, 32, 112, 112]               0\n",
      "            Conv2d-4         [-1, 32, 112, 112]             288\n",
      "       BatchNorm2d-5         [-1, 32, 112, 112]              64\n",
      "              ReLU-6         [-1, 32, 112, 112]               0\n",
      "            Conv2d-7         [-1, 64, 112, 112]           2,112\n",
      "       BatchNorm2d-8         [-1, 64, 112, 112]             128\n",
      "              ReLU-9         [-1, 64, 112, 112]               0\n",
      "          Sepconv-10         [-1, 64, 112, 112]               0\n",
      "           Conv2d-11           [-1, 64, 56, 56]             576\n",
      "      BatchNorm2d-12           [-1, 64, 56, 56]             128\n",
      "             ReLU-13           [-1, 64, 56, 56]               0\n",
      "           Conv2d-14          [-1, 128, 56, 56]           8,320\n",
      "      BatchNorm2d-15          [-1, 128, 56, 56]             256\n",
      "             ReLU-16          [-1, 128, 56, 56]               0\n",
      "          Sepconv-17          [-1, 128, 56, 56]               0\n",
      "           Conv2d-18          [-1, 128, 56, 56]           1,152\n",
      "      BatchNorm2d-19          [-1, 128, 56, 56]             256\n",
      "             ReLU-20          [-1, 128, 56, 56]               0\n",
      "           Conv2d-21          [-1, 128, 56, 56]          16,512\n",
      "      BatchNorm2d-22          [-1, 128, 56, 56]             256\n",
      "             ReLU-23          [-1, 128, 56, 56]               0\n",
      "          Sepconv-24          [-1, 128, 56, 56]               0\n",
      "           Conv2d-25          [-1, 128, 28, 28]           1,152\n",
      "      BatchNorm2d-26          [-1, 128, 28, 28]             256\n",
      "             ReLU-27          [-1, 128, 28, 28]               0\n",
      "           Conv2d-28          [-1, 256, 28, 28]          33,024\n",
      "      BatchNorm2d-29          [-1, 256, 28, 28]             512\n",
      "             ReLU-30          [-1, 256, 28, 28]               0\n",
      "          Sepconv-31          [-1, 256, 28, 28]               0\n",
      "           Conv2d-32          [-1, 256, 28, 28]           2,304\n",
      "      BatchNorm2d-33          [-1, 256, 28, 28]             512\n",
      "             ReLU-34          [-1, 256, 28, 28]               0\n",
      "           Conv2d-35          [-1, 256, 28, 28]          65,792\n",
      "      BatchNorm2d-36          [-1, 256, 28, 28]             512\n",
      "             ReLU-37          [-1, 256, 28, 28]               0\n",
      "          Sepconv-38          [-1, 256, 28, 28]               0\n",
      "           Conv2d-39          [-1, 256, 14, 14]           2,304\n",
      "      BatchNorm2d-40          [-1, 256, 14, 14]             512\n",
      "             ReLU-41          [-1, 256, 14, 14]               0\n",
      "           Conv2d-42          [-1, 512, 14, 14]         131,584\n",
      "      BatchNorm2d-43          [-1, 512, 14, 14]           1,024\n",
      "             ReLU-44          [-1, 512, 14, 14]               0\n",
      "          Sepconv-45          [-1, 512, 14, 14]               0\n",
      "           Conv2d-46          [-1, 512, 14, 14]           4,608\n",
      "      BatchNorm2d-47          [-1, 512, 14, 14]           1,024\n",
      "             ReLU-48          [-1, 512, 14, 14]               0\n",
      "           Conv2d-49          [-1, 512, 14, 14]         262,656\n",
      "      BatchNorm2d-50          [-1, 512, 14, 14]           1,024\n",
      "             ReLU-51          [-1, 512, 14, 14]               0\n",
      "          Sepconv-52          [-1, 512, 14, 14]               0\n",
      "           Conv2d-53          [-1, 512, 14, 14]           4,608\n",
      "      BatchNorm2d-54          [-1, 512, 14, 14]           1,024\n",
      "             ReLU-55          [-1, 512, 14, 14]               0\n",
      "           Conv2d-56          [-1, 512, 14, 14]         262,656\n",
      "      BatchNorm2d-57          [-1, 512, 14, 14]           1,024\n",
      "             ReLU-58          [-1, 512, 14, 14]               0\n",
      "          Sepconv-59          [-1, 512, 14, 14]               0\n",
      "           Conv2d-60          [-1, 512, 14, 14]           4,608\n",
      "      BatchNorm2d-61          [-1, 512, 14, 14]           1,024\n",
      "             ReLU-62          [-1, 512, 14, 14]               0\n",
      "           Conv2d-63          [-1, 512, 14, 14]         262,656\n",
      "      BatchNorm2d-64          [-1, 512, 14, 14]           1,024\n",
      "             ReLU-65          [-1, 512, 14, 14]               0\n",
      "          Sepconv-66          [-1, 512, 14, 14]               0\n",
      "           Conv2d-67          [-1, 512, 14, 14]           4,608\n",
      "      BatchNorm2d-68          [-1, 512, 14, 14]           1,024\n",
      "             ReLU-69          [-1, 512, 14, 14]               0\n",
      "           Conv2d-70          [-1, 512, 14, 14]         262,656\n",
      "      BatchNorm2d-71          [-1, 512, 14, 14]           1,024\n",
      "             ReLU-72          [-1, 512, 14, 14]               0\n",
      "          Sepconv-73          [-1, 512, 14, 14]               0\n",
      "           Conv2d-74          [-1, 512, 14, 14]           4,608\n",
      "      BatchNorm2d-75          [-1, 512, 14, 14]           1,024\n",
      "             ReLU-76          [-1, 512, 14, 14]               0\n",
      "           Conv2d-77          [-1, 512, 14, 14]         262,656\n",
      "      BatchNorm2d-78          [-1, 512, 14, 14]           1,024\n",
      "             ReLU-79          [-1, 512, 14, 14]               0\n",
      "          Sepconv-80          [-1, 512, 14, 14]               0\n",
      "           Conv2d-81            [-1, 512, 7, 7]           4,608\n",
      "      BatchNorm2d-82            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-83            [-1, 512, 7, 7]               0\n",
      "           Conv2d-84           [-1, 1024, 7, 7]         525,312\n",
      "      BatchNorm2d-85           [-1, 1024, 7, 7]           2,048\n",
      "             ReLU-86           [-1, 1024, 7, 7]               0\n",
      "          Sepconv-87           [-1, 1024, 7, 7]               0\n",
      "           Conv2d-88           [-1, 1024, 4, 4]           9,216\n",
      "      BatchNorm2d-89           [-1, 1024, 4, 4]           2,048\n",
      "             ReLU-90           [-1, 1024, 4, 4]               0\n",
      "           Conv2d-91           [-1, 1024, 4, 4]       1,049,600\n",
      "      BatchNorm2d-92           [-1, 1024, 4, 4]           2,048\n",
      "             ReLU-93           [-1, 1024, 4, 4]               0\n",
      "          Sepconv-94           [-1, 1024, 4, 4]               0\n",
      "AdaptiveAvgPool2d-95           [-1, 1024, 1, 1]               0\n",
      "             View-96                 [-1, 1024]               0\n",
      "           Linear-97                 [-1, 1000]       1,025,000\n",
      "================================================================\n",
      "Total params: 4,237,928\n",
      "Trainable params: 4,237,928\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 134.31\n",
      "Params size (MB): 16.17\n",
      "Estimated Total Size (MB): 151.05\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 파이토치 \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Sepconv(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1):\n",
    "        super(Sepconv, self).__init__()\n",
    "        layers = []\n",
    "        layers += [nn.Conv2d(in_channels=in_channels, out_channels=in_channels, kernel_size=kernel_size, \n",
    "                             stride=stride, padding=padding, groups=in_channels, bias=False),\n",
    "                   nn.BatchNorm2d(in_channels),\n",
    "                   nn.ReLU(True),\n",
    "                   nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=1),\n",
    "                   nn.BatchNorm2d(out_channels),\n",
    "                   nn.ReLU(True)]\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "class MobileNet(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels=3, out_channels=1000):\n",
    "        super(MobileNet, self).__init__()\n",
    "        layers = []\n",
    "        layers += [nn.Conv2d(in_channels=in_channels, out_channels=32, kernel_size=3, stride=2, padding=1, bias=False),\n",
    "                   nn.BatchNorm2d(32),\n",
    "                   nn.ReLU(True),\n",
    "                   Sepconv(32, 64),\n",
    "                   Sepconv(64, 128, stride=2),\n",
    "                   Sepconv(128, 128),\n",
    "                   Sepconv(128, 256, stride=2),\n",
    "                   Sepconv(256, 256),\n",
    "                   Sepconv(256, 512, stride=2)]\n",
    "        for i in range(5):\n",
    "            layers += [Sepconv(512, 512)]\n",
    "        layers += [Sepconv(512, 1024, stride=2),\n",
    "                   Sepconv(1024, 1024, stride=2),\n",
    "                   nn.AdaptiveAvgPool2d((1,1)),\n",
    "                   View(-1),\n",
    "                   nn.Linear(1024, out_channels)]\n",
    "\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "class View(nn.Module):\n",
    "\n",
    "    def __init__(self, *shape):\n",
    "        super(View, self).__init__()\n",
    "        self.shape = shape\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.view(x.shape[0], *self.shape)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    from torchsummary import summary\n",
    "    model = MobileNet()\n",
    "    summary(model, (3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 112, 112, 32)      864       \n",
      "_________________________________________________________________\n",
      "batch_normalization_85 (Batc (None, 112, 112, 32)      128       \n",
      "_________________________________________________________________\n",
      "activation_85 (Activation)   (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_79 (Separab (None, 112, 112, 64)      2336      \n",
      "_________________________________________________________________\n",
      "batch_normalization_86 (Batc (None, 112, 112, 64)      256       \n",
      "_________________________________________________________________\n",
      "activation_86 (Activation)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_80 (Separab (None, 56, 56, 128)       8768      \n",
      "_________________________________________________________________\n",
      "batch_normalization_87 (Batc (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_87 (Activation)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_81 (Separab (None, 56, 56, 128)       17536     \n",
      "_________________________________________________________________\n",
      "batch_normalization_88 (Batc (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_88 (Activation)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_82 (Separab (None, 28, 28, 256)       33920     \n",
      "_________________________________________________________________\n",
      "batch_normalization_89 (Batc (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_89 (Activation)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_83 (Separab (None, 28, 28, 256)       67840     \n",
      "_________________________________________________________________\n",
      "batch_normalization_90 (Batc (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_90 (Activation)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_84 (Separab (None, 14, 14, 512)       133376    \n",
      "_________________________________________________________________\n",
      "batch_normalization_91 (Batc (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_91 (Activation)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_85 (Separab (None, 14, 14, 512)       266752    \n",
      "_________________________________________________________________\n",
      "batch_normalization_92 (Batc (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_92 (Activation)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_86 (Separab (None, 14, 14, 512)       266752    \n",
      "_________________________________________________________________\n",
      "batch_normalization_93 (Batc (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_93 (Activation)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_87 (Separab (None, 14, 14, 512)       266752    \n",
      "_________________________________________________________________\n",
      "batch_normalization_94 (Batc (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_94 (Activation)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_88 (Separab (None, 14, 14, 512)       266752    \n",
      "_________________________________________________________________\n",
      "batch_normalization_95 (Batc (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_95 (Activation)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_89 (Separab (None, 14, 14, 512)       266752    \n",
      "_________________________________________________________________\n",
      "batch_normalization_96 (Batc (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_96 (Activation)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_90 (Separab (None, 7, 7, 1024)        528896    \n",
      "_________________________________________________________________\n",
      "batch_normalization_97 (Batc (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "activation_97 (Activation)   (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_91 (Separab (None, 4, 4, 1024)        1057792   \n",
      "_________________________________________________________________\n",
      "batch_normalization_98 (Batc (None, 4, 4, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "activation_98 (Activation)   (None, 4, 4, 1024)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_4 (Average (None, 4, 4, 1024)        0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 16384)             0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1000)              16385000  \n",
      "=================================================================\n",
      "Total params: 19,594,024\n",
      "Trainable params: 19,582,056\n",
      "Non-trainable params: 11,968\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 케라스\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, SeparableConv2D, Conv2D, BatchNormalization, Activation, Dense, AveragePooling2D, Flatten\n",
    "\n",
    "def Depthwise_Separable_Conv(pre_layer, dw_num_ch, s):\n",
    "    x = SeparableConv2D(dw_num_ch, 3, strides=s, padding='same', use_bias=False)(pre_layer)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "def MobileNet():\n",
    "    inputs = Input(shape=(224, 224, 3))\n",
    "    \n",
    "    x = Conv2D(32, kernel_size=3, strides=2, padding='same', use_bias=False)(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Depthwise_Separable_Conv(x, 64, 1) # 두 번째는 output 채널 수\n",
    "    x = Depthwise_Separable_Conv(x, 128, 2)\n",
    "    x = Depthwise_Separable_Conv(x, 128,1)\n",
    "    x = Depthwise_Separable_Conv(x, 256, 2)\n",
    "    x = Depthwise_Separable_Conv(x, 256, 1)\n",
    "    x = Depthwise_Separable_Conv(x, 512, 2)\n",
    "    \n",
    "    for num in range(0, 5):\n",
    "        x = Depthwise_Separable_Conv(x, 512, 1)\n",
    "        \n",
    "    x = Depthwise_Separable_Conv(x, 1024, 2)\n",
    "    x = Depthwise_Separable_Conv(x, 1024, 2)\n",
    "    x = AveragePooling2D(pool_size=1)(x)\n",
    "    x = Flatten()(x)\n",
    "    outputs = Dense(1000, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs, outputs)\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = MobileNet()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
