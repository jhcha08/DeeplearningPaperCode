{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 16, 16]           9,408\n",
      "       BatchNorm2d-2           [-1, 64, 16, 16]             128\n",
      "              ReLU-3           [-1, 64, 16, 16]               0\n",
      "         MaxPool2d-4             [-1, 64, 8, 8]               0\n",
      "       BatchNorm2d-5             [-1, 64, 8, 8]             128\n",
      "              ReLU-6             [-1, 64, 8, 8]               0\n",
      "            Conv2d-7            [-1, 128, 8, 8]           8,192\n",
      "       BatchNorm2d-8            [-1, 128, 8, 8]             256\n",
      "              ReLU-9            [-1, 128, 8, 8]               0\n",
      "           Conv2d-10             [-1, 32, 8, 8]          36,864\n",
      "       Bottleneck-11             [-1, 96, 8, 8]               0\n",
      "      BatchNorm2d-12             [-1, 96, 8, 8]             192\n",
      "             ReLU-13             [-1, 96, 8, 8]               0\n",
      "           Conv2d-14            [-1, 128, 8, 8]          12,288\n",
      "      BatchNorm2d-15            [-1, 128, 8, 8]             256\n",
      "             ReLU-16            [-1, 128, 8, 8]               0\n",
      "           Conv2d-17             [-1, 32, 8, 8]          36,864\n",
      "       Bottleneck-18            [-1, 128, 8, 8]               0\n",
      "      BatchNorm2d-19            [-1, 128, 8, 8]             256\n",
      "             ReLU-20            [-1, 128, 8, 8]               0\n",
      "           Conv2d-21            [-1, 128, 8, 8]          16,384\n",
      "      BatchNorm2d-22            [-1, 128, 8, 8]             256\n",
      "             ReLU-23            [-1, 128, 8, 8]               0\n",
      "           Conv2d-24             [-1, 32, 8, 8]          36,864\n",
      "       Bottleneck-25            [-1, 160, 8, 8]               0\n",
      "      BatchNorm2d-26            [-1, 160, 8, 8]             320\n",
      "             ReLU-27            [-1, 160, 8, 8]               0\n",
      "           Conv2d-28            [-1, 128, 8, 8]          20,480\n",
      "      BatchNorm2d-29            [-1, 128, 8, 8]             256\n",
      "             ReLU-30            [-1, 128, 8, 8]               0\n",
      "           Conv2d-31             [-1, 32, 8, 8]          36,864\n",
      "       Bottleneck-32            [-1, 192, 8, 8]               0\n",
      "      BatchNorm2d-33            [-1, 192, 8, 8]             384\n",
      "             ReLU-34            [-1, 192, 8, 8]               0\n",
      "           Conv2d-35            [-1, 128, 8, 8]          24,576\n",
      "      BatchNorm2d-36            [-1, 128, 8, 8]             256\n",
      "             ReLU-37            [-1, 128, 8, 8]               0\n",
      "           Conv2d-38             [-1, 32, 8, 8]          36,864\n",
      "       Bottleneck-39            [-1, 224, 8, 8]               0\n",
      "      BatchNorm2d-40            [-1, 224, 8, 8]             448\n",
      "             ReLU-41            [-1, 224, 8, 8]               0\n",
      "           Conv2d-42            [-1, 128, 8, 8]          28,672\n",
      "      BatchNorm2d-43            [-1, 128, 8, 8]             256\n",
      "             ReLU-44            [-1, 128, 8, 8]               0\n",
      "           Conv2d-45             [-1, 32, 8, 8]          36,864\n",
      "       Bottleneck-46            [-1, 256, 8, 8]               0\n",
      "       DenseBlock-47            [-1, 256, 8, 8]               0\n",
      "      BatchNorm2d-48            [-1, 256, 8, 8]             512\n",
      "             ReLU-49            [-1, 256, 8, 8]               0\n",
      "           Conv2d-50            [-1, 128, 8, 8]         294,912\n",
      "        AvgPool2d-51            [-1, 128, 4, 4]               0\n",
      " Transition_layer-52            [-1, 128, 4, 4]               0\n",
      "      BatchNorm2d-53            [-1, 128, 4, 4]             256\n",
      "             ReLU-54            [-1, 128, 4, 4]               0\n",
      "           Conv2d-55            [-1, 128, 4, 4]          16,384\n",
      "      BatchNorm2d-56            [-1, 128, 4, 4]             256\n",
      "             ReLU-57            [-1, 128, 4, 4]               0\n",
      "           Conv2d-58             [-1, 32, 4, 4]          36,864\n",
      "       Bottleneck-59            [-1, 160, 4, 4]               0\n",
      "      BatchNorm2d-60            [-1, 160, 4, 4]             320\n",
      "             ReLU-61            [-1, 160, 4, 4]               0\n",
      "           Conv2d-62            [-1, 128, 4, 4]          20,480\n",
      "      BatchNorm2d-63            [-1, 128, 4, 4]             256\n",
      "             ReLU-64            [-1, 128, 4, 4]               0\n",
      "           Conv2d-65             [-1, 32, 4, 4]          36,864\n",
      "       Bottleneck-66            [-1, 192, 4, 4]               0\n",
      "      BatchNorm2d-67            [-1, 192, 4, 4]             384\n",
      "             ReLU-68            [-1, 192, 4, 4]               0\n",
      "           Conv2d-69            [-1, 128, 4, 4]          24,576\n",
      "      BatchNorm2d-70            [-1, 128, 4, 4]             256\n",
      "             ReLU-71            [-1, 128, 4, 4]               0\n",
      "           Conv2d-72             [-1, 32, 4, 4]          36,864\n",
      "       Bottleneck-73            [-1, 224, 4, 4]               0\n",
      "      BatchNorm2d-74            [-1, 224, 4, 4]             448\n",
      "             ReLU-75            [-1, 224, 4, 4]               0\n",
      "           Conv2d-76            [-1, 128, 4, 4]          28,672\n",
      "      BatchNorm2d-77            [-1, 128, 4, 4]             256\n",
      "             ReLU-78            [-1, 128, 4, 4]               0\n",
      "           Conv2d-79             [-1, 32, 4, 4]          36,864\n",
      "       Bottleneck-80            [-1, 256, 4, 4]               0\n",
      "      BatchNorm2d-81            [-1, 256, 4, 4]             512\n",
      "             ReLU-82            [-1, 256, 4, 4]               0\n",
      "           Conv2d-83            [-1, 128, 4, 4]          32,768\n",
      "      BatchNorm2d-84            [-1, 128, 4, 4]             256\n",
      "             ReLU-85            [-1, 128, 4, 4]               0\n",
      "           Conv2d-86             [-1, 32, 4, 4]          36,864\n",
      "       Bottleneck-87            [-1, 288, 4, 4]               0\n",
      "      BatchNorm2d-88            [-1, 288, 4, 4]             576\n",
      "             ReLU-89            [-1, 288, 4, 4]               0\n",
      "           Conv2d-90            [-1, 128, 4, 4]          36,864\n",
      "      BatchNorm2d-91            [-1, 128, 4, 4]             256\n",
      "             ReLU-92            [-1, 128, 4, 4]               0\n",
      "           Conv2d-93             [-1, 32, 4, 4]          36,864\n",
      "       Bottleneck-94            [-1, 320, 4, 4]               0\n",
      "      BatchNorm2d-95            [-1, 320, 4, 4]             640\n",
      "             ReLU-96            [-1, 320, 4, 4]               0\n",
      "           Conv2d-97            [-1, 128, 4, 4]          40,960\n",
      "      BatchNorm2d-98            [-1, 128, 4, 4]             256\n",
      "             ReLU-99            [-1, 128, 4, 4]               0\n",
      "          Conv2d-100             [-1, 32, 4, 4]          36,864\n",
      "      Bottleneck-101            [-1, 352, 4, 4]               0\n",
      "     BatchNorm2d-102            [-1, 352, 4, 4]             704\n",
      "            ReLU-103            [-1, 352, 4, 4]               0\n",
      "          Conv2d-104            [-1, 128, 4, 4]          45,056\n",
      "     BatchNorm2d-105            [-1, 128, 4, 4]             256\n",
      "            ReLU-106            [-1, 128, 4, 4]               0\n",
      "          Conv2d-107             [-1, 32, 4, 4]          36,864\n",
      "      Bottleneck-108            [-1, 384, 4, 4]               0\n",
      "     BatchNorm2d-109            [-1, 384, 4, 4]             768\n",
      "            ReLU-110            [-1, 384, 4, 4]               0\n",
      "          Conv2d-111            [-1, 128, 4, 4]          49,152\n",
      "     BatchNorm2d-112            [-1, 128, 4, 4]             256\n",
      "            ReLU-113            [-1, 128, 4, 4]               0\n",
      "          Conv2d-114             [-1, 32, 4, 4]          36,864\n",
      "      Bottleneck-115            [-1, 416, 4, 4]               0\n",
      "     BatchNorm2d-116            [-1, 416, 4, 4]             832\n",
      "            ReLU-117            [-1, 416, 4, 4]               0\n",
      "          Conv2d-118            [-1, 128, 4, 4]          53,248\n",
      "     BatchNorm2d-119            [-1, 128, 4, 4]             256\n",
      "            ReLU-120            [-1, 128, 4, 4]               0\n",
      "          Conv2d-121             [-1, 32, 4, 4]          36,864\n",
      "      Bottleneck-122            [-1, 448, 4, 4]               0\n",
      "     BatchNorm2d-123            [-1, 448, 4, 4]             896\n",
      "            ReLU-124            [-1, 448, 4, 4]               0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Conv2d-125            [-1, 128, 4, 4]          57,344\n",
      "     BatchNorm2d-126            [-1, 128, 4, 4]             256\n",
      "            ReLU-127            [-1, 128, 4, 4]               0\n",
      "          Conv2d-128             [-1, 32, 4, 4]          36,864\n",
      "      Bottleneck-129            [-1, 480, 4, 4]               0\n",
      "     BatchNorm2d-130            [-1, 480, 4, 4]             960\n",
      "            ReLU-131            [-1, 480, 4, 4]               0\n",
      "          Conv2d-132            [-1, 128, 4, 4]          61,440\n",
      "     BatchNorm2d-133            [-1, 128, 4, 4]             256\n",
      "            ReLU-134            [-1, 128, 4, 4]               0\n",
      "          Conv2d-135             [-1, 32, 4, 4]          36,864\n",
      "      Bottleneck-136            [-1, 512, 4, 4]               0\n",
      "      DenseBlock-137            [-1, 512, 4, 4]               0\n",
      "     BatchNorm2d-138            [-1, 512, 4, 4]           1,024\n",
      "            ReLU-139            [-1, 512, 4, 4]               0\n",
      "          Conv2d-140            [-1, 256, 4, 4]       1,179,648\n",
      "       AvgPool2d-141            [-1, 256, 2, 2]               0\n",
      "Transition_layer-142            [-1, 256, 2, 2]               0\n",
      "     BatchNorm2d-143            [-1, 256, 2, 2]             512\n",
      "            ReLU-144            [-1, 256, 2, 2]               0\n",
      "          Conv2d-145            [-1, 128, 2, 2]          32,768\n",
      "     BatchNorm2d-146            [-1, 128, 2, 2]             256\n",
      "            ReLU-147            [-1, 128, 2, 2]               0\n",
      "          Conv2d-148             [-1, 32, 2, 2]          36,864\n",
      "      Bottleneck-149            [-1, 288, 2, 2]               0\n",
      "     BatchNorm2d-150            [-1, 288, 2, 2]             576\n",
      "            ReLU-151            [-1, 288, 2, 2]               0\n",
      "          Conv2d-152            [-1, 128, 2, 2]          36,864\n",
      "     BatchNorm2d-153            [-1, 128, 2, 2]             256\n",
      "            ReLU-154            [-1, 128, 2, 2]               0\n",
      "          Conv2d-155             [-1, 32, 2, 2]          36,864\n",
      "      Bottleneck-156            [-1, 320, 2, 2]               0\n",
      "     BatchNorm2d-157            [-1, 320, 2, 2]             640\n",
      "            ReLU-158            [-1, 320, 2, 2]               0\n",
      "          Conv2d-159            [-1, 128, 2, 2]          40,960\n",
      "     BatchNorm2d-160            [-1, 128, 2, 2]             256\n",
      "            ReLU-161            [-1, 128, 2, 2]               0\n",
      "          Conv2d-162             [-1, 32, 2, 2]          36,864\n",
      "      Bottleneck-163            [-1, 352, 2, 2]               0\n",
      "     BatchNorm2d-164            [-1, 352, 2, 2]             704\n",
      "            ReLU-165            [-1, 352, 2, 2]               0\n",
      "          Conv2d-166            [-1, 128, 2, 2]          45,056\n",
      "     BatchNorm2d-167            [-1, 128, 2, 2]             256\n",
      "            ReLU-168            [-1, 128, 2, 2]               0\n",
      "          Conv2d-169             [-1, 32, 2, 2]          36,864\n",
      "      Bottleneck-170            [-1, 384, 2, 2]               0\n",
      "     BatchNorm2d-171            [-1, 384, 2, 2]             768\n",
      "            ReLU-172            [-1, 384, 2, 2]               0\n",
      "          Conv2d-173            [-1, 128, 2, 2]          49,152\n",
      "     BatchNorm2d-174            [-1, 128, 2, 2]             256\n",
      "            ReLU-175            [-1, 128, 2, 2]               0\n",
      "          Conv2d-176             [-1, 32, 2, 2]          36,864\n",
      "      Bottleneck-177            [-1, 416, 2, 2]               0\n",
      "     BatchNorm2d-178            [-1, 416, 2, 2]             832\n",
      "            ReLU-179            [-1, 416, 2, 2]               0\n",
      "          Conv2d-180            [-1, 128, 2, 2]          53,248\n",
      "     BatchNorm2d-181            [-1, 128, 2, 2]             256\n",
      "            ReLU-182            [-1, 128, 2, 2]               0\n",
      "          Conv2d-183             [-1, 32, 2, 2]          36,864\n",
      "      Bottleneck-184            [-1, 448, 2, 2]               0\n",
      "     BatchNorm2d-185            [-1, 448, 2, 2]             896\n",
      "            ReLU-186            [-1, 448, 2, 2]               0\n",
      "          Conv2d-187            [-1, 128, 2, 2]          57,344\n",
      "     BatchNorm2d-188            [-1, 128, 2, 2]             256\n",
      "            ReLU-189            [-1, 128, 2, 2]               0\n",
      "          Conv2d-190             [-1, 32, 2, 2]          36,864\n",
      "      Bottleneck-191            [-1, 480, 2, 2]               0\n",
      "     BatchNorm2d-192            [-1, 480, 2, 2]             960\n",
      "            ReLU-193            [-1, 480, 2, 2]               0\n",
      "          Conv2d-194            [-1, 128, 2, 2]          61,440\n",
      "     BatchNorm2d-195            [-1, 128, 2, 2]             256\n",
      "            ReLU-196            [-1, 128, 2, 2]               0\n",
      "          Conv2d-197             [-1, 32, 2, 2]          36,864\n",
      "      Bottleneck-198            [-1, 512, 2, 2]               0\n",
      "     BatchNorm2d-199            [-1, 512, 2, 2]           1,024\n",
      "            ReLU-200            [-1, 512, 2, 2]               0\n",
      "          Conv2d-201            [-1, 128, 2, 2]          65,536\n",
      "     BatchNorm2d-202            [-1, 128, 2, 2]             256\n",
      "            ReLU-203            [-1, 128, 2, 2]               0\n",
      "          Conv2d-204             [-1, 32, 2, 2]          36,864\n",
      "      Bottleneck-205            [-1, 544, 2, 2]               0\n",
      "     BatchNorm2d-206            [-1, 544, 2, 2]           1,088\n",
      "            ReLU-207            [-1, 544, 2, 2]               0\n",
      "          Conv2d-208            [-1, 128, 2, 2]          69,632\n",
      "     BatchNorm2d-209            [-1, 128, 2, 2]             256\n",
      "            ReLU-210            [-1, 128, 2, 2]               0\n",
      "          Conv2d-211             [-1, 32, 2, 2]          36,864\n",
      "      Bottleneck-212            [-1, 576, 2, 2]               0\n",
      "     BatchNorm2d-213            [-1, 576, 2, 2]           1,152\n",
      "            ReLU-214            [-1, 576, 2, 2]               0\n",
      "          Conv2d-215            [-1, 128, 2, 2]          73,728\n",
      "     BatchNorm2d-216            [-1, 128, 2, 2]             256\n",
      "            ReLU-217            [-1, 128, 2, 2]               0\n",
      "          Conv2d-218             [-1, 32, 2, 2]          36,864\n",
      "      Bottleneck-219            [-1, 608, 2, 2]               0\n",
      "     BatchNorm2d-220            [-1, 608, 2, 2]           1,216\n",
      "            ReLU-221            [-1, 608, 2, 2]               0\n",
      "          Conv2d-222            [-1, 128, 2, 2]          77,824\n",
      "     BatchNorm2d-223            [-1, 128, 2, 2]             256\n",
      "            ReLU-224            [-1, 128, 2, 2]               0\n",
      "          Conv2d-225             [-1, 32, 2, 2]          36,864\n",
      "      Bottleneck-226            [-1, 640, 2, 2]               0\n",
      "     BatchNorm2d-227            [-1, 640, 2, 2]           1,280\n",
      "            ReLU-228            [-1, 640, 2, 2]               0\n",
      "          Conv2d-229            [-1, 128, 2, 2]          81,920\n",
      "     BatchNorm2d-230            [-1, 128, 2, 2]             256\n",
      "            ReLU-231            [-1, 128, 2, 2]               0\n",
      "          Conv2d-232             [-1, 32, 2, 2]          36,864\n",
      "      Bottleneck-233            [-1, 672, 2, 2]               0\n",
      "     BatchNorm2d-234            [-1, 672, 2, 2]           1,344\n",
      "            ReLU-235            [-1, 672, 2, 2]               0\n",
      "          Conv2d-236            [-1, 128, 2, 2]          86,016\n",
      "     BatchNorm2d-237            [-1, 128, 2, 2]             256\n",
      "            ReLU-238            [-1, 128, 2, 2]               0\n",
      "          Conv2d-239             [-1, 32, 2, 2]          36,864\n",
      "      Bottleneck-240            [-1, 704, 2, 2]               0\n",
      "     BatchNorm2d-241            [-1, 704, 2, 2]           1,408\n",
      "            ReLU-242            [-1, 704, 2, 2]               0\n",
      "          Conv2d-243            [-1, 128, 2, 2]          90,112\n",
      "     BatchNorm2d-244            [-1, 128, 2, 2]             256\n",
      "            ReLU-245            [-1, 128, 2, 2]               0\n",
      "          Conv2d-246             [-1, 32, 2, 2]          36,864\n",
      "      Bottleneck-247            [-1, 736, 2, 2]               0\n",
      "     BatchNorm2d-248            [-1, 736, 2, 2]           1,472\n",
      "            ReLU-249            [-1, 736, 2, 2]               0\n",
      "          Conv2d-250            [-1, 128, 2, 2]          94,208\n",
      "     BatchNorm2d-251            [-1, 128, 2, 2]             256\n",
      "            ReLU-252            [-1, 128, 2, 2]               0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Conv2d-253             [-1, 32, 2, 2]          36,864\n",
      "      Bottleneck-254            [-1, 768, 2, 2]               0\n",
      "     BatchNorm2d-255            [-1, 768, 2, 2]           1,536\n",
      "            ReLU-256            [-1, 768, 2, 2]               0\n",
      "          Conv2d-257            [-1, 128, 2, 2]          98,304\n",
      "     BatchNorm2d-258            [-1, 128, 2, 2]             256\n",
      "            ReLU-259            [-1, 128, 2, 2]               0\n",
      "          Conv2d-260             [-1, 32, 2, 2]          36,864\n",
      "      Bottleneck-261            [-1, 800, 2, 2]               0\n",
      "     BatchNorm2d-262            [-1, 800, 2, 2]           1,600\n",
      "            ReLU-263            [-1, 800, 2, 2]               0\n",
      "          Conv2d-264            [-1, 128, 2, 2]         102,400\n",
      "     BatchNorm2d-265            [-1, 128, 2, 2]             256\n",
      "            ReLU-266            [-1, 128, 2, 2]               0\n",
      "          Conv2d-267             [-1, 32, 2, 2]          36,864\n",
      "      Bottleneck-268            [-1, 832, 2, 2]               0\n",
      "     BatchNorm2d-269            [-1, 832, 2, 2]           1,664\n",
      "            ReLU-270            [-1, 832, 2, 2]               0\n",
      "          Conv2d-271            [-1, 128, 2, 2]         106,496\n",
      "     BatchNorm2d-272            [-1, 128, 2, 2]             256\n",
      "            ReLU-273            [-1, 128, 2, 2]               0\n",
      "          Conv2d-274             [-1, 32, 2, 2]          36,864\n",
      "      Bottleneck-275            [-1, 864, 2, 2]               0\n",
      "     BatchNorm2d-276            [-1, 864, 2, 2]           1,728\n",
      "            ReLU-277            [-1, 864, 2, 2]               0\n",
      "          Conv2d-278            [-1, 128, 2, 2]         110,592\n",
      "     BatchNorm2d-279            [-1, 128, 2, 2]             256\n",
      "            ReLU-280            [-1, 128, 2, 2]               0\n",
      "          Conv2d-281             [-1, 32, 2, 2]          36,864\n",
      "      Bottleneck-282            [-1, 896, 2, 2]               0\n",
      "     BatchNorm2d-283            [-1, 896, 2, 2]           1,792\n",
      "            ReLU-284            [-1, 896, 2, 2]               0\n",
      "          Conv2d-285            [-1, 128, 2, 2]         114,688\n",
      "     BatchNorm2d-286            [-1, 128, 2, 2]             256\n",
      "            ReLU-287            [-1, 128, 2, 2]               0\n",
      "          Conv2d-288             [-1, 32, 2, 2]          36,864\n",
      "      Bottleneck-289            [-1, 928, 2, 2]               0\n",
      "     BatchNorm2d-290            [-1, 928, 2, 2]           1,856\n",
      "            ReLU-291            [-1, 928, 2, 2]               0\n",
      "          Conv2d-292            [-1, 128, 2, 2]         118,784\n",
      "     BatchNorm2d-293            [-1, 128, 2, 2]             256\n",
      "            ReLU-294            [-1, 128, 2, 2]               0\n",
      "          Conv2d-295             [-1, 32, 2, 2]          36,864\n",
      "      Bottleneck-296            [-1, 960, 2, 2]               0\n",
      "     BatchNorm2d-297            [-1, 960, 2, 2]           1,920\n",
      "            ReLU-298            [-1, 960, 2, 2]               0\n",
      "          Conv2d-299            [-1, 128, 2, 2]         122,880\n",
      "     BatchNorm2d-300            [-1, 128, 2, 2]             256\n",
      "            ReLU-301            [-1, 128, 2, 2]               0\n",
      "          Conv2d-302             [-1, 32, 2, 2]          36,864\n",
      "      Bottleneck-303            [-1, 992, 2, 2]               0\n",
      "     BatchNorm2d-304            [-1, 992, 2, 2]           1,984\n",
      "            ReLU-305            [-1, 992, 2, 2]               0\n",
      "          Conv2d-306            [-1, 128, 2, 2]         126,976\n",
      "     BatchNorm2d-307            [-1, 128, 2, 2]             256\n",
      "            ReLU-308            [-1, 128, 2, 2]               0\n",
      "          Conv2d-309             [-1, 32, 2, 2]          36,864\n",
      "      Bottleneck-310           [-1, 1024, 2, 2]               0\n",
      "      DenseBlock-311           [-1, 1024, 2, 2]               0\n",
      "     BatchNorm2d-312           [-1, 1024, 2, 2]           2,048\n",
      "            ReLU-313           [-1, 1024, 2, 2]               0\n",
      "          Conv2d-314            [-1, 512, 2, 2]       4,718,592\n",
      "       AvgPool2d-315            [-1, 512, 1, 1]               0\n",
      "Transition_layer-316            [-1, 512, 1, 1]               0\n",
      "     BatchNorm2d-317            [-1, 512, 1, 1]           1,024\n",
      "            ReLU-318            [-1, 512, 1, 1]               0\n",
      "          Conv2d-319            [-1, 128, 1, 1]          65,536\n",
      "     BatchNorm2d-320            [-1, 128, 1, 1]             256\n",
      "            ReLU-321            [-1, 128, 1, 1]               0\n",
      "          Conv2d-322             [-1, 32, 1, 1]          36,864\n",
      "      Bottleneck-323            [-1, 544, 1, 1]               0\n",
      "     BatchNorm2d-324            [-1, 544, 1, 1]           1,088\n",
      "            ReLU-325            [-1, 544, 1, 1]               0\n",
      "          Conv2d-326            [-1, 128, 1, 1]          69,632\n",
      "     BatchNorm2d-327            [-1, 128, 1, 1]             256\n",
      "            ReLU-328            [-1, 128, 1, 1]               0\n",
      "          Conv2d-329             [-1, 32, 1, 1]          36,864\n",
      "      Bottleneck-330            [-1, 576, 1, 1]               0\n",
      "     BatchNorm2d-331            [-1, 576, 1, 1]           1,152\n",
      "            ReLU-332            [-1, 576, 1, 1]               0\n",
      "          Conv2d-333            [-1, 128, 1, 1]          73,728\n",
      "     BatchNorm2d-334            [-1, 128, 1, 1]             256\n",
      "            ReLU-335            [-1, 128, 1, 1]               0\n",
      "          Conv2d-336             [-1, 32, 1, 1]          36,864\n",
      "      Bottleneck-337            [-1, 608, 1, 1]               0\n",
      "     BatchNorm2d-338            [-1, 608, 1, 1]           1,216\n",
      "            ReLU-339            [-1, 608, 1, 1]               0\n",
      "          Conv2d-340            [-1, 128, 1, 1]          77,824\n",
      "     BatchNorm2d-341            [-1, 128, 1, 1]             256\n",
      "            ReLU-342            [-1, 128, 1, 1]               0\n",
      "          Conv2d-343             [-1, 32, 1, 1]          36,864\n",
      "      Bottleneck-344            [-1, 640, 1, 1]               0\n",
      "     BatchNorm2d-345            [-1, 640, 1, 1]           1,280\n",
      "            ReLU-346            [-1, 640, 1, 1]               0\n",
      "          Conv2d-347            [-1, 128, 1, 1]          81,920\n",
      "     BatchNorm2d-348            [-1, 128, 1, 1]             256\n",
      "            ReLU-349            [-1, 128, 1, 1]               0\n",
      "          Conv2d-350             [-1, 32, 1, 1]          36,864\n",
      "      Bottleneck-351            [-1, 672, 1, 1]               0\n",
      "     BatchNorm2d-352            [-1, 672, 1, 1]           1,344\n",
      "            ReLU-353            [-1, 672, 1, 1]               0\n",
      "          Conv2d-354            [-1, 128, 1, 1]          86,016\n",
      "     BatchNorm2d-355            [-1, 128, 1, 1]             256\n",
      "            ReLU-356            [-1, 128, 1, 1]               0\n",
      "          Conv2d-357             [-1, 32, 1, 1]          36,864\n",
      "      Bottleneck-358            [-1, 704, 1, 1]               0\n",
      "     BatchNorm2d-359            [-1, 704, 1, 1]           1,408\n",
      "            ReLU-360            [-1, 704, 1, 1]               0\n",
      "          Conv2d-361            [-1, 128, 1, 1]          90,112\n",
      "     BatchNorm2d-362            [-1, 128, 1, 1]             256\n",
      "            ReLU-363            [-1, 128, 1, 1]               0\n",
      "          Conv2d-364             [-1, 32, 1, 1]          36,864\n",
      "      Bottleneck-365            [-1, 736, 1, 1]               0\n",
      "     BatchNorm2d-366            [-1, 736, 1, 1]           1,472\n",
      "            ReLU-367            [-1, 736, 1, 1]               0\n",
      "          Conv2d-368            [-1, 128, 1, 1]          94,208\n",
      "     BatchNorm2d-369            [-1, 128, 1, 1]             256\n",
      "            ReLU-370            [-1, 128, 1, 1]               0\n",
      "          Conv2d-371             [-1, 32, 1, 1]          36,864\n",
      "      Bottleneck-372            [-1, 768, 1, 1]               0\n",
      "     BatchNorm2d-373            [-1, 768, 1, 1]           1,536\n",
      "            ReLU-374            [-1, 768, 1, 1]               0\n",
      "          Conv2d-375            [-1, 128, 1, 1]          98,304\n",
      "     BatchNorm2d-376            [-1, 128, 1, 1]             256\n",
      "            ReLU-377            [-1, 128, 1, 1]               0\n",
      "          Conv2d-378             [-1, 32, 1, 1]          36,864\n",
      "      Bottleneck-379            [-1, 800, 1, 1]               0\n",
      "     BatchNorm2d-380            [-1, 800, 1, 1]           1,600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            ReLU-381            [-1, 800, 1, 1]               0\n",
      "          Conv2d-382            [-1, 128, 1, 1]         102,400\n",
      "     BatchNorm2d-383            [-1, 128, 1, 1]             256\n",
      "            ReLU-384            [-1, 128, 1, 1]               0\n",
      "          Conv2d-385             [-1, 32, 1, 1]          36,864\n",
      "      Bottleneck-386            [-1, 832, 1, 1]               0\n",
      "     BatchNorm2d-387            [-1, 832, 1, 1]           1,664\n",
      "            ReLU-388            [-1, 832, 1, 1]               0\n",
      "          Conv2d-389            [-1, 128, 1, 1]         106,496\n",
      "     BatchNorm2d-390            [-1, 128, 1, 1]             256\n",
      "            ReLU-391            [-1, 128, 1, 1]               0\n",
      "          Conv2d-392             [-1, 32, 1, 1]          36,864\n",
      "      Bottleneck-393            [-1, 864, 1, 1]               0\n",
      "     BatchNorm2d-394            [-1, 864, 1, 1]           1,728\n",
      "            ReLU-395            [-1, 864, 1, 1]               0\n",
      "          Conv2d-396            [-1, 128, 1, 1]         110,592\n",
      "     BatchNorm2d-397            [-1, 128, 1, 1]             256\n",
      "            ReLU-398            [-1, 128, 1, 1]               0\n",
      "          Conv2d-399             [-1, 32, 1, 1]          36,864\n",
      "      Bottleneck-400            [-1, 896, 1, 1]               0\n",
      "     BatchNorm2d-401            [-1, 896, 1, 1]           1,792\n",
      "            ReLU-402            [-1, 896, 1, 1]               0\n",
      "          Conv2d-403            [-1, 128, 1, 1]         114,688\n",
      "     BatchNorm2d-404            [-1, 128, 1, 1]             256\n",
      "            ReLU-405            [-1, 128, 1, 1]               0\n",
      "          Conv2d-406             [-1, 32, 1, 1]          36,864\n",
      "      Bottleneck-407            [-1, 928, 1, 1]               0\n",
      "     BatchNorm2d-408            [-1, 928, 1, 1]           1,856\n",
      "            ReLU-409            [-1, 928, 1, 1]               0\n",
      "          Conv2d-410            [-1, 128, 1, 1]         118,784\n",
      "     BatchNorm2d-411            [-1, 128, 1, 1]             256\n",
      "            ReLU-412            [-1, 128, 1, 1]               0\n",
      "          Conv2d-413             [-1, 32, 1, 1]          36,864\n",
      "      Bottleneck-414            [-1, 960, 1, 1]               0\n",
      "     BatchNorm2d-415            [-1, 960, 1, 1]           1,920\n",
      "            ReLU-416            [-1, 960, 1, 1]               0\n",
      "          Conv2d-417            [-1, 128, 1, 1]         122,880\n",
      "     BatchNorm2d-418            [-1, 128, 1, 1]             256\n",
      "            ReLU-419            [-1, 128, 1, 1]               0\n",
      "          Conv2d-420             [-1, 32, 1, 1]          36,864\n",
      "      Bottleneck-421            [-1, 992, 1, 1]               0\n",
      "     BatchNorm2d-422            [-1, 992, 1, 1]           1,984\n",
      "            ReLU-423            [-1, 992, 1, 1]               0\n",
      "          Conv2d-424            [-1, 128, 1, 1]         126,976\n",
      "     BatchNorm2d-425            [-1, 128, 1, 1]             256\n",
      "            ReLU-426            [-1, 128, 1, 1]               0\n",
      "          Conv2d-427             [-1, 32, 1, 1]          36,864\n",
      "      Bottleneck-428           [-1, 1024, 1, 1]               0\n",
      "      DenseBlock-429           [-1, 1024, 1, 1]               0\n",
      "AdaptiveAvgPool2d-430           [-1, 1024, 1, 1]               0\n",
      "            View-431                 [-1, 1024]               0\n",
      "          Linear-432                   [-1, 10]          10,250\n",
      "================================================================\n",
      "Total params: 12,467,082\n",
      "Trainable params: 12,467,082\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 7.85\n",
      "Params size (MB): 47.56\n",
      "Estimated Total Size (MB): 55.42\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 파이토치\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "\n",
    "    def __init__(self, in_ch, growth_rate):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        layers = []\n",
    "        layers += [nn.BatchNorm2d(in_ch),\n",
    "                   nn.ReLU(True),\n",
    "                   nn.Conv2d(in_ch, growth_rate*4, kernel_size=1, bias=False),\n",
    "                   nn.BatchNorm2d(growth_rate*4),\n",
    "                   nn.ReLU(True),\n",
    "                   nn.Conv2d(growth_rate*4, growth_rate, kernel_size=3, stride=1, padding=1, bias=False)]\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layers(x)\n",
    "        out = torch.cat((x, out), dim=1)\n",
    "        return out\n",
    "\n",
    "class DenseBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, n_layers, n_ch, growth_rate):\n",
    "        super(DenseBlock, self).__init__()\n",
    "\n",
    "        for i in range(n_layers):\n",
    "            setattr(self, \"Dense_layer_{}\".format(i), Bottleneck(n_ch + i * growth_rate, growth_rate))\n",
    "\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i in range(self.n_layers):\n",
    "            x = getattr(self, \"Dense_layer_{}\".format(i))(x)\n",
    "        return x\n",
    "\n",
    "class Transition_layer(nn.Module):\n",
    "\n",
    "    def __init__(self, in_ch):\n",
    "        super(Transition_layer, self).__init__()\n",
    "        num_ch = int(in_ch*0.5)\n",
    "        layers = []\n",
    "        layers += [nn.BatchNorm2d(in_ch),\n",
    "                   nn.ReLU(True),\n",
    "                   nn.Conv2d(in_ch, num_ch, kernel_size=3, padding=1, bias=False),\n",
    "                   nn.AvgPool2d(kernel_size=2, stride=2)]\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "class DenseNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(DenseNet, self).__init__()\n",
    "        layers = []\n",
    "        layers += [nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False),\n",
    "                   nn.BatchNorm2d(64),\n",
    "                   nn.ReLU(True),\n",
    "                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
    "                   DenseBlock(6, 64, 32),\n",
    "                   Transition_layer(256),\n",
    "                   DenseBlock(12, 128, 32),\n",
    "                   Transition_layer(512),\n",
    "                   DenseBlock(24, 256, 32),\n",
    "                   Transition_layer(1024),\n",
    "                   DenseBlock(16, 512, 32),\n",
    "                   nn.AdaptiveAvgPool2d((1, 1)),\n",
    "                   View(-1),\n",
    "                   nn.Linear(1024, 10)]\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        return x\n",
    "\n",
    "class View(nn.Module):\n",
    "\n",
    "    def __init__(self, *shape):\n",
    "        super(View, self).__init__()\n",
    "        self.shape = shape\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.view(x.shape[0], *self.shape)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    from torchsummary import summary\n",
    "    model = DenseNet()\n",
    "    summary(model, (3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 112, 112, 64) 9408        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 112, 112, 64) 256         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 112, 112, 64) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 56, 56, 64)   0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 56, 56, 64)   256         max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 56, 56, 64)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 56, 56, 128)  8192        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 56, 56, 128)  512         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 56, 56, 128)  0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 56, 56, 32)   36864       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 56, 56, 96)   0           max_pooling2d_1[0][0]            \n",
      "                                                                 conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 56, 56, 96)   384         concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 56, 56, 96)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 56, 56, 128)  12288       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 56, 56, 128)  512         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 56, 56, 128)  0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 56, 56, 32)   36864       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 56, 56, 128)  0           max_pooling2d_1[0][0]            \n",
      "                                                                 conv2d_3[0][0]                   \n",
      "                                                                 conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 56, 56, 128)  512         concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 56, 56, 128)  0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 56, 56, 128)  16384       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 56, 56, 128)  512         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 56, 56, 128)  0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 56, 56, 32)   36864       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 56, 56, 160)  0           max_pooling2d_1[0][0]            \n",
      "                                                                 conv2d_3[0][0]                   \n",
      "                                                                 conv2d_5[0][0]                   \n",
      "                                                                 conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 56, 56, 160)  640         concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 56, 56, 160)  0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 56, 56, 128)  20480       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 56, 56, 128)  512         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 56, 56, 128)  0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 56, 56, 32)   36864       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 56, 56, 192)  0           max_pooling2d_1[0][0]            \n",
      "                                                                 conv2d_3[0][0]                   \n",
      "                                                                 conv2d_5[0][0]                   \n",
      "                                                                 conv2d_7[0][0]                   \n",
      "                                                                 conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 56, 56, 192)  768         concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 56, 56, 192)  0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 56, 56, 128)  24576       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 56, 56, 128)  512         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 56, 56, 128)  0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 56, 56, 32)   36864       activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 56, 56, 224)  0           max_pooling2d_1[0][0]            \n",
      "                                                                 conv2d_3[0][0]                   \n",
      "                                                                 conv2d_5[0][0]                   \n",
      "                                                                 conv2d_7[0][0]                   \n",
      "                                                                 conv2d_9[0][0]                   \n",
      "                                                                 conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 56, 56, 224)  896         concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 56, 56, 224)  0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 56, 56, 128)  28672       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 56, 56, 128)  512         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 56, 56, 128)  0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 56, 56, 32)   36864       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 56, 56, 256)  0           max_pooling2d_1[0][0]            \n",
      "                                                                 conv2d_3[0][0]                   \n",
      "                                                                 conv2d_5[0][0]                   \n",
      "                                                                 conv2d_7[0][0]                   \n",
      "                                                                 conv2d_9[0][0]                   \n",
      "                                                                 conv2d_11[0][0]                  \n",
      "                                                                 conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 56, 56, 256)  1024        concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 56, 56, 256)  0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 56, 56, 128)  294912      activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "transition_layer_1 (AveragePool (None, 28, 28, 128)  0           conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 28, 28, 128)  512         transition_layer_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 28, 28, 128)  0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 28, 28, 128)  16384       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 28, 28, 128)  512         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 28, 28, 128)  0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 28, 28, 32)   36864       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 28, 28, 160)  0           transition_layer_1[0][0]         \n",
      "                                                                 conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 28, 28, 160)  640         concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 28, 28, 160)  0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 28, 28, 128)  20480       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 28, 28, 128)  512         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 28, 28, 128)  0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 28, 28, 32)   36864       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 28, 28, 192)  0           transition_layer_1[0][0]         \n",
      "                                                                 conv2d_16[0][0]                  \n",
      "                                                                 conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 28, 28, 192)  768         concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 28, 28, 192)  0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 28, 28, 128)  24576       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 28, 28, 128)  512         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 28, 28, 128)  0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 28, 28, 32)   36864       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 28, 28, 224)  0           transition_layer_1[0][0]         \n",
      "                                                                 conv2d_16[0][0]                  \n",
      "                                                                 conv2d_18[0][0]                  \n",
      "                                                                 conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 28, 28, 224)  896         concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 28, 28, 224)  0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 28, 28, 128)  28672       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 28, 28, 128)  512         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 28, 28, 128)  0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 28, 28, 32)   36864       activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 28, 28, 256)  0           transition_layer_1[0][0]         \n",
      "                                                                 conv2d_16[0][0]                  \n",
      "                                                                 conv2d_18[0][0]                  \n",
      "                                                                 conv2d_20[0][0]                  \n",
      "                                                                 conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 28, 28, 256)  1024        concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 28, 28, 256)  0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 28, 28, 128)  32768       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 28, 28, 128)  512         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 28, 28, 128)  0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 28, 28, 32)   36864       activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 28, 28, 288)  0           transition_layer_1[0][0]         \n",
      "                                                                 conv2d_16[0][0]                  \n",
      "                                                                 conv2d_18[0][0]                  \n",
      "                                                                 conv2d_20[0][0]                  \n",
      "                                                                 conv2d_22[0][0]                  \n",
      "                                                                 conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 28, 28, 288)  1152        concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 28, 28, 288)  0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 28, 28, 128)  36864       activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 28, 28, 128)  512         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 28, 28, 128)  0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 28, 28, 32)   36864       activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 28, 28, 320)  0           transition_layer_1[0][0]         \n",
      "                                                                 conv2d_16[0][0]                  \n",
      "                                                                 conv2d_18[0][0]                  \n",
      "                                                                 conv2d_20[0][0]                  \n",
      "                                                                 conv2d_22[0][0]                  \n",
      "                                                                 conv2d_24[0][0]                  \n",
      "                                                                 conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 28, 28, 320)  1280        concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 28, 28, 320)  0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 28, 28, 128)  40960       activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 28, 28, 128)  512         conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 28, 28, 128)  0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 28, 28, 32)   36864       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 28, 28, 352)  0           transition_layer_1[0][0]         \n",
      "                                                                 conv2d_16[0][0]                  \n",
      "                                                                 conv2d_18[0][0]                  \n",
      "                                                                 conv2d_20[0][0]                  \n",
      "                                                                 conv2d_22[0][0]                  \n",
      "                                                                 conv2d_24[0][0]                  \n",
      "                                                                 conv2d_26[0][0]                  \n",
      "                                                                 conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 28, 28, 352)  1408        concatenate_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 28, 28, 352)  0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 28, 28, 128)  45056       activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 28, 28, 128)  512         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 28, 28, 128)  0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 28, 28, 32)   36864       activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)    (None, 28, 28, 384)  0           transition_layer_1[0][0]         \n",
      "                                                                 conv2d_16[0][0]                  \n",
      "                                                                 conv2d_18[0][0]                  \n",
      "                                                                 conv2d_20[0][0]                  \n",
      "                                                                 conv2d_22[0][0]                  \n",
      "                                                                 conv2d_24[0][0]                  \n",
      "                                                                 conv2d_26[0][0]                  \n",
      "                                                                 conv2d_28[0][0]                  \n",
      "                                                                 conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 28, 28, 384)  1536        concatenate_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 28, 28, 384)  0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 28, 28, 128)  49152       activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 28, 28, 128)  512         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 28, 28, 128)  0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 28, 28, 32)   36864       activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)    (None, 28, 28, 416)  0           transition_layer_1[0][0]         \n",
      "                                                                 conv2d_16[0][0]                  \n",
      "                                                                 conv2d_18[0][0]                  \n",
      "                                                                 conv2d_20[0][0]                  \n",
      "                                                                 conv2d_22[0][0]                  \n",
      "                                                                 conv2d_24[0][0]                  \n",
      "                                                                 conv2d_26[0][0]                  \n",
      "                                                                 conv2d_28[0][0]                  \n",
      "                                                                 conv2d_30[0][0]                  \n",
      "                                                                 conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 28, 28, 416)  1664        concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 28, 28, 416)  0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 28, 28, 128)  53248       activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 28, 28, 128)  512         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 28, 28, 128)  0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 28, 28, 32)   36864       activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_16 (Concatenate)    (None, 28, 28, 448)  0           transition_layer_1[0][0]         \n",
      "                                                                 conv2d_16[0][0]                  \n",
      "                                                                 conv2d_18[0][0]                  \n",
      "                                                                 conv2d_20[0][0]                  \n",
      "                                                                 conv2d_22[0][0]                  \n",
      "                                                                 conv2d_24[0][0]                  \n",
      "                                                                 conv2d_26[0][0]                  \n",
      "                                                                 conv2d_28[0][0]                  \n",
      "                                                                 conv2d_30[0][0]                  \n",
      "                                                                 conv2d_32[0][0]                  \n",
      "                                                                 conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 28, 28, 448)  1792        concatenate_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 28, 28, 448)  0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 28, 28, 128)  57344       activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 28, 28, 128)  512         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 28, 28, 128)  0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 28, 28, 32)   36864       activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_17 (Concatenate)    (None, 28, 28, 480)  0           transition_layer_1[0][0]         \n",
      "                                                                 conv2d_16[0][0]                  \n",
      "                                                                 conv2d_18[0][0]                  \n",
      "                                                                 conv2d_20[0][0]                  \n",
      "                                                                 conv2d_22[0][0]                  \n",
      "                                                                 conv2d_24[0][0]                  \n",
      "                                                                 conv2d_26[0][0]                  \n",
      "                                                                 conv2d_28[0][0]                  \n",
      "                                                                 conv2d_30[0][0]                  \n",
      "                                                                 conv2d_32[0][0]                  \n",
      "                                                                 conv2d_34[0][0]                  \n",
      "                                                                 conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 28, 28, 480)  1920        concatenate_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 28, 28, 480)  0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 28, 28, 128)  61440       activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 28, 28, 128)  512         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 28, 28, 128)  0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 28, 28, 32)   36864       activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_18 (Concatenate)    (None, 28, 28, 512)  0           transition_layer_1[0][0]         \n",
      "                                                                 conv2d_16[0][0]                  \n",
      "                                                                 conv2d_18[0][0]                  \n",
      "                                                                 conv2d_20[0][0]                  \n",
      "                                                                 conv2d_22[0][0]                  \n",
      "                                                                 conv2d_24[0][0]                  \n",
      "                                                                 conv2d_26[0][0]                  \n",
      "                                                                 conv2d_28[0][0]                  \n",
      "                                                                 conv2d_30[0][0]                  \n",
      "                                                                 conv2d_32[0][0]                  \n",
      "                                                                 conv2d_34[0][0]                  \n",
      "                                                                 conv2d_36[0][0]                  \n",
      "                                                                 conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 28, 28, 512)  2048        concatenate_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 28, 28, 512)  0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 28, 28, 256)  1179648     activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "transition_layer_2 (AveragePool (None, 14, 14, 256)  0           conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 14, 14, 256)  1024        transition_layer_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 14, 14, 256)  0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 14, 14, 128)  32768       activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 14, 14, 128)  512         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 14, 14, 128)  0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 14, 14, 32)   36864       activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_19 (Concatenate)    (None, 14, 14, 288)  0           transition_layer_2[0][0]         \n",
      "                                                                 conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 14, 14, 288)  1152        concatenate_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 14, 14, 288)  0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 14, 14, 128)  36864       activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 14, 14, 128)  512         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 14, 14, 128)  0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 14, 14, 32)   36864       activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_20 (Concatenate)    (None, 14, 14, 320)  0           transition_layer_2[0][0]         \n",
      "                                                                 conv2d_41[0][0]                  \n",
      "                                                                 conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 14, 14, 320)  1280        concatenate_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 14, 14, 320)  0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 14, 14, 128)  40960       activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 14, 14, 128)  512         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 14, 14, 128)  0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 14, 14, 32)   36864       activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_21 (Concatenate)    (None, 14, 14, 352)  0           transition_layer_2[0][0]         \n",
      "                                                                 conv2d_41[0][0]                  \n",
      "                                                                 conv2d_43[0][0]                  \n",
      "                                                                 conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 14, 14, 352)  1408        concatenate_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 14, 14, 352)  0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 14, 14, 128)  45056       activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 14, 14, 128)  512         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 14, 14, 128)  0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 14, 14, 32)   36864       activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_22 (Concatenate)    (None, 14, 14, 384)  0           transition_layer_2[0][0]         \n",
      "                                                                 conv2d_41[0][0]                  \n",
      "                                                                 conv2d_43[0][0]                  \n",
      "                                                                 conv2d_45[0][0]                  \n",
      "                                                                 conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 14, 14, 384)  1536        concatenate_22[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 14, 14, 384)  0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 14, 14, 128)  49152       activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 14, 14, 128)  512         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 14, 14, 128)  0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 14, 14, 32)   36864       activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_23 (Concatenate)    (None, 14, 14, 416)  0           transition_layer_2[0][0]         \n",
      "                                                                 conv2d_41[0][0]                  \n",
      "                                                                 conv2d_43[0][0]                  \n",
      "                                                                 conv2d_45[0][0]                  \n",
      "                                                                 conv2d_47[0][0]                  \n",
      "                                                                 conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 14, 14, 416)  1664        concatenate_23[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 14, 14, 416)  0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 14, 14, 128)  53248       activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 14, 14, 128)  512         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 14, 14, 128)  0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 14, 14, 32)   36864       activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_24 (Concatenate)    (None, 14, 14, 448)  0           transition_layer_2[0][0]         \n",
      "                                                                 conv2d_41[0][0]                  \n",
      "                                                                 conv2d_43[0][0]                  \n",
      "                                                                 conv2d_45[0][0]                  \n",
      "                                                                 conv2d_47[0][0]                  \n",
      "                                                                 conv2d_49[0][0]                  \n",
      "                                                                 conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 14, 14, 448)  1792        concatenate_24[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 14, 14, 448)  0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 14, 14, 128)  57344       activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 14, 14, 128)  512         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 14, 14, 128)  0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 14, 14, 32)   36864       activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_25 (Concatenate)    (None, 14, 14, 480)  0           transition_layer_2[0][0]         \n",
      "                                                                 conv2d_41[0][0]                  \n",
      "                                                                 conv2d_43[0][0]                  \n",
      "                                                                 conv2d_45[0][0]                  \n",
      "                                                                 conv2d_47[0][0]                  \n",
      "                                                                 conv2d_49[0][0]                  \n",
      "                                                                 conv2d_51[0][0]                  \n",
      "                                                                 conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 14, 14, 480)  1920        concatenate_25[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 14, 14, 480)  0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 14, 14, 128)  61440       activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 14, 14, 128)  512         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 14, 14, 128)  0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 14, 14, 32)   36864       activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_26 (Concatenate)    (None, 14, 14, 512)  0           transition_layer_2[0][0]         \n",
      "                                                                 conv2d_41[0][0]                  \n",
      "                                                                 conv2d_43[0][0]                  \n",
      "                                                                 conv2d_45[0][0]                  \n",
      "                                                                 conv2d_47[0][0]                  \n",
      "                                                                 conv2d_49[0][0]                  \n",
      "                                                                 conv2d_51[0][0]                  \n",
      "                                                                 conv2d_53[0][0]                  \n",
      "                                                                 conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 14, 14, 512)  2048        concatenate_26[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 14, 14, 512)  0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 14, 14, 128)  65536       activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 14, 14, 128)  512         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 14, 14, 128)  0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 14, 14, 32)   36864       activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_27 (Concatenate)    (None, 14, 14, 544)  0           transition_layer_2[0][0]         \n",
      "                                                                 conv2d_41[0][0]                  \n",
      "                                                                 conv2d_43[0][0]                  \n",
      "                                                                 conv2d_45[0][0]                  \n",
      "                                                                 conv2d_47[0][0]                  \n",
      "                                                                 conv2d_49[0][0]                  \n",
      "                                                                 conv2d_51[0][0]                  \n",
      "                                                                 conv2d_53[0][0]                  \n",
      "                                                                 conv2d_55[0][0]                  \n",
      "                                                                 conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 14, 14, 544)  2176        concatenate_27[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 14, 14, 544)  0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 14, 14, 128)  69632       activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 14, 14, 128)  512         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 14, 14, 128)  0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 14, 14, 32)   36864       activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_28 (Concatenate)    (None, 14, 14, 576)  0           transition_layer_2[0][0]         \n",
      "                                                                 conv2d_41[0][0]                  \n",
      "                                                                 conv2d_43[0][0]                  \n",
      "                                                                 conv2d_45[0][0]                  \n",
      "                                                                 conv2d_47[0][0]                  \n",
      "                                                                 conv2d_49[0][0]                  \n",
      "                                                                 conv2d_51[0][0]                  \n",
      "                                                                 conv2d_53[0][0]                  \n",
      "                                                                 conv2d_55[0][0]                  \n",
      "                                                                 conv2d_57[0][0]                  \n",
      "                                                                 conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 14, 14, 576)  2304        concatenate_28[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 14, 14, 576)  0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 14, 14, 128)  73728       activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 14, 14, 128)  512         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 14, 14, 128)  0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 14, 14, 32)   36864       activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_29 (Concatenate)    (None, 14, 14, 608)  0           transition_layer_2[0][0]         \n",
      "                                                                 conv2d_41[0][0]                  \n",
      "                                                                 conv2d_43[0][0]                  \n",
      "                                                                 conv2d_45[0][0]                  \n",
      "                                                                 conv2d_47[0][0]                  \n",
      "                                                                 conv2d_49[0][0]                  \n",
      "                                                                 conv2d_51[0][0]                  \n",
      "                                                                 conv2d_53[0][0]                  \n",
      "                                                                 conv2d_55[0][0]                  \n",
      "                                                                 conv2d_57[0][0]                  \n",
      "                                                                 conv2d_59[0][0]                  \n",
      "                                                                 conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 14, 14, 608)  2432        concatenate_29[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 14, 14, 608)  0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 14, 14, 128)  77824       activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 14, 14, 128)  512         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 14, 14, 128)  0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 14, 14, 32)   36864       activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_30 (Concatenate)    (None, 14, 14, 640)  0           transition_layer_2[0][0]         \n",
      "                                                                 conv2d_41[0][0]                  \n",
      "                                                                 conv2d_43[0][0]                  \n",
      "                                                                 conv2d_45[0][0]                  \n",
      "                                                                 conv2d_47[0][0]                  \n",
      "                                                                 conv2d_49[0][0]                  \n",
      "                                                                 conv2d_51[0][0]                  \n",
      "                                                                 conv2d_53[0][0]                  \n",
      "                                                                 conv2d_55[0][0]                  \n",
      "                                                                 conv2d_57[0][0]                  \n",
      "                                                                 conv2d_59[0][0]                  \n",
      "                                                                 conv2d_61[0][0]                  \n",
      "                                                                 conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 14, 14, 640)  2560        concatenate_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 14, 14, 640)  0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 14, 14, 128)  81920       activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 14, 14, 128)  512         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 14, 14, 128)  0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 14, 14, 32)   36864       activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_31 (Concatenate)    (None, 14, 14, 672)  0           transition_layer_2[0][0]         \n",
      "                                                                 conv2d_41[0][0]                  \n",
      "                                                                 conv2d_43[0][0]                  \n",
      "                                                                 conv2d_45[0][0]                  \n",
      "                                                                 conv2d_47[0][0]                  \n",
      "                                                                 conv2d_49[0][0]                  \n",
      "                                                                 conv2d_51[0][0]                  \n",
      "                                                                 conv2d_53[0][0]                  \n",
      "                                                                 conv2d_55[0][0]                  \n",
      "                                                                 conv2d_57[0][0]                  \n",
      "                                                                 conv2d_59[0][0]                  \n",
      "                                                                 conv2d_61[0][0]                  \n",
      "                                                                 conv2d_63[0][0]                  \n",
      "                                                                 conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 14, 14, 672)  2688        concatenate_31[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 14, 14, 672)  0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 14, 14, 128)  86016       activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 14, 14, 128)  512         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 14, 14, 128)  0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 14, 14, 32)   36864       activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_32 (Concatenate)    (None, 14, 14, 704)  0           transition_layer_2[0][0]         \n",
      "                                                                 conv2d_41[0][0]                  \n",
      "                                                                 conv2d_43[0][0]                  \n",
      "                                                                 conv2d_45[0][0]                  \n",
      "                                                                 conv2d_47[0][0]                  \n",
      "                                                                 conv2d_49[0][0]                  \n",
      "                                                                 conv2d_51[0][0]                  \n",
      "                                                                 conv2d_53[0][0]                  \n",
      "                                                                 conv2d_55[0][0]                  \n",
      "                                                                 conv2d_57[0][0]                  \n",
      "                                                                 conv2d_59[0][0]                  \n",
      "                                                                 conv2d_61[0][0]                  \n",
      "                                                                 conv2d_63[0][0]                  \n",
      "                                                                 conv2d_65[0][0]                  \n",
      "                                                                 conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 14, 14, 704)  2816        concatenate_32[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 14, 14, 704)  0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 14, 14, 128)  90112       activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 14, 14, 128)  512         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 14, 14, 128)  0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 14, 14, 32)   36864       activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_33 (Concatenate)    (None, 14, 14, 736)  0           transition_layer_2[0][0]         \n",
      "                                                                 conv2d_41[0][0]                  \n",
      "                                                                 conv2d_43[0][0]                  \n",
      "                                                                 conv2d_45[0][0]                  \n",
      "                                                                 conv2d_47[0][0]                  \n",
      "                                                                 conv2d_49[0][0]                  \n",
      "                                                                 conv2d_51[0][0]                  \n",
      "                                                                 conv2d_53[0][0]                  \n",
      "                                                                 conv2d_55[0][0]                  \n",
      "                                                                 conv2d_57[0][0]                  \n",
      "                                                                 conv2d_59[0][0]                  \n",
      "                                                                 conv2d_61[0][0]                  \n",
      "                                                                 conv2d_63[0][0]                  \n",
      "                                                                 conv2d_65[0][0]                  \n",
      "                                                                 conv2d_67[0][0]                  \n",
      "                                                                 conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 14, 14, 736)  2944        concatenate_33[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 14, 14, 736)  0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 14, 14, 128)  94208       activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 14, 14, 128)  512         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 14, 14, 128)  0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 14, 14, 32)   36864       activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_34 (Concatenate)    (None, 14, 14, 768)  0           transition_layer_2[0][0]         \n",
      "                                                                 conv2d_41[0][0]                  \n",
      "                                                                 conv2d_43[0][0]                  \n",
      "                                                                 conv2d_45[0][0]                  \n",
      "                                                                 conv2d_47[0][0]                  \n",
      "                                                                 conv2d_49[0][0]                  \n",
      "                                                                 conv2d_51[0][0]                  \n",
      "                                                                 conv2d_53[0][0]                  \n",
      "                                                                 conv2d_55[0][0]                  \n",
      "                                                                 conv2d_57[0][0]                  \n",
      "                                                                 conv2d_59[0][0]                  \n",
      "                                                                 conv2d_61[0][0]                  \n",
      "                                                                 conv2d_63[0][0]                  \n",
      "                                                                 conv2d_65[0][0]                  \n",
      "                                                                 conv2d_67[0][0]                  \n",
      "                                                                 conv2d_69[0][0]                  \n",
      "                                                                 conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 14, 14, 768)  3072        concatenate_34[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 14, 14, 768)  0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 14, 14, 128)  98304       activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 14, 14, 128)  512         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 14, 14, 128)  0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 14, 14, 32)   36864       activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_35 (Concatenate)    (None, 14, 14, 800)  0           transition_layer_2[0][0]         \n",
      "                                                                 conv2d_41[0][0]                  \n",
      "                                                                 conv2d_43[0][0]                  \n",
      "                                                                 conv2d_45[0][0]                  \n",
      "                                                                 conv2d_47[0][0]                  \n",
      "                                                                 conv2d_49[0][0]                  \n",
      "                                                                 conv2d_51[0][0]                  \n",
      "                                                                 conv2d_53[0][0]                  \n",
      "                                                                 conv2d_55[0][0]                  \n",
      "                                                                 conv2d_57[0][0]                  \n",
      "                                                                 conv2d_59[0][0]                  \n",
      "                                                                 conv2d_61[0][0]                  \n",
      "                                                                 conv2d_63[0][0]                  \n",
      "                                                                 conv2d_65[0][0]                  \n",
      "                                                                 conv2d_67[0][0]                  \n",
      "                                                                 conv2d_69[0][0]                  \n",
      "                                                                 conv2d_71[0][0]                  \n",
      "                                                                 conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 14, 14, 800)  3200        concatenate_35[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 14, 14, 800)  0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 14, 14, 128)  102400      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 14, 14, 128)  512         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 14, 14, 128)  0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 14, 14, 32)   36864       activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_36 (Concatenate)    (None, 14, 14, 832)  0           transition_layer_2[0][0]         \n",
      "                                                                 conv2d_41[0][0]                  \n",
      "                                                                 conv2d_43[0][0]                  \n",
      "                                                                 conv2d_45[0][0]                  \n",
      "                                                                 conv2d_47[0][0]                  \n",
      "                                                                 conv2d_49[0][0]                  \n",
      "                                                                 conv2d_51[0][0]                  \n",
      "                                                                 conv2d_53[0][0]                  \n",
      "                                                                 conv2d_55[0][0]                  \n",
      "                                                                 conv2d_57[0][0]                  \n",
      "                                                                 conv2d_59[0][0]                  \n",
      "                                                                 conv2d_61[0][0]                  \n",
      "                                                                 conv2d_63[0][0]                  \n",
      "                                                                 conv2d_65[0][0]                  \n",
      "                                                                 conv2d_67[0][0]                  \n",
      "                                                                 conv2d_69[0][0]                  \n",
      "                                                                 conv2d_71[0][0]                  \n",
      "                                                                 conv2d_73[0][0]                  \n",
      "                                                                 conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 14, 14, 832)  3328        concatenate_36[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 14, 14, 832)  0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 14, 14, 128)  106496      activation_76[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 14, 14, 128)  512         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 14, 14, 128)  0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 14, 14, 32)   36864       activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_37 (Concatenate)    (None, 14, 14, 864)  0           transition_layer_2[0][0]         \n",
      "                                                                 conv2d_41[0][0]                  \n",
      "                                                                 conv2d_43[0][0]                  \n",
      "                                                                 conv2d_45[0][0]                  \n",
      "                                                                 conv2d_47[0][0]                  \n",
      "                                                                 conv2d_49[0][0]                  \n",
      "                                                                 conv2d_51[0][0]                  \n",
      "                                                                 conv2d_53[0][0]                  \n",
      "                                                                 conv2d_55[0][0]                  \n",
      "                                                                 conv2d_57[0][0]                  \n",
      "                                                                 conv2d_59[0][0]                  \n",
      "                                                                 conv2d_61[0][0]                  \n",
      "                                                                 conv2d_63[0][0]                  \n",
      "                                                                 conv2d_65[0][0]                  \n",
      "                                                                 conv2d_67[0][0]                  \n",
      "                                                                 conv2d_69[0][0]                  \n",
      "                                                                 conv2d_71[0][0]                  \n",
      "                                                                 conv2d_73[0][0]                  \n",
      "                                                                 conv2d_75[0][0]                  \n",
      "                                                                 conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 14, 14, 864)  3456        concatenate_37[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 14, 14, 864)  0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 14, 14, 128)  110592      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 14, 14, 128)  512         conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 14, 14, 128)  0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 14, 14, 32)   36864       activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_38 (Concatenate)    (None, 14, 14, 896)  0           transition_layer_2[0][0]         \n",
      "                                                                 conv2d_41[0][0]                  \n",
      "                                                                 conv2d_43[0][0]                  \n",
      "                                                                 conv2d_45[0][0]                  \n",
      "                                                                 conv2d_47[0][0]                  \n",
      "                                                                 conv2d_49[0][0]                  \n",
      "                                                                 conv2d_51[0][0]                  \n",
      "                                                                 conv2d_53[0][0]                  \n",
      "                                                                 conv2d_55[0][0]                  \n",
      "                                                                 conv2d_57[0][0]                  \n",
      "                                                                 conv2d_59[0][0]                  \n",
      "                                                                 conv2d_61[0][0]                  \n",
      "                                                                 conv2d_63[0][0]                  \n",
      "                                                                 conv2d_65[0][0]                  \n",
      "                                                                 conv2d_67[0][0]                  \n",
      "                                                                 conv2d_69[0][0]                  \n",
      "                                                                 conv2d_71[0][0]                  \n",
      "                                                                 conv2d_73[0][0]                  \n",
      "                                                                 conv2d_75[0][0]                  \n",
      "                                                                 conv2d_77[0][0]                  \n",
      "                                                                 conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 14, 14, 896)  3584        concatenate_38[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 14, 14, 896)  0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 14, 14, 128)  114688      activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 14, 14, 128)  512         conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activation_81 (Activation)      (None, 14, 14, 128)  0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 14, 14, 32)   36864       activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_39 (Concatenate)    (None, 14, 14, 928)  0           transition_layer_2[0][0]         \n",
      "                                                                 conv2d_41[0][0]                  \n",
      "                                                                 conv2d_43[0][0]                  \n",
      "                                                                 conv2d_45[0][0]                  \n",
      "                                                                 conv2d_47[0][0]                  \n",
      "                                                                 conv2d_49[0][0]                  \n",
      "                                                                 conv2d_51[0][0]                  \n",
      "                                                                 conv2d_53[0][0]                  \n",
      "                                                                 conv2d_55[0][0]                  \n",
      "                                                                 conv2d_57[0][0]                  \n",
      "                                                                 conv2d_59[0][0]                  \n",
      "                                                                 conv2d_61[0][0]                  \n",
      "                                                                 conv2d_63[0][0]                  \n",
      "                                                                 conv2d_65[0][0]                  \n",
      "                                                                 conv2d_67[0][0]                  \n",
      "                                                                 conv2d_69[0][0]                  \n",
      "                                                                 conv2d_71[0][0]                  \n",
      "                                                                 conv2d_73[0][0]                  \n",
      "                                                                 conv2d_75[0][0]                  \n",
      "                                                                 conv2d_77[0][0]                  \n",
      "                                                                 conv2d_79[0][0]                  \n",
      "                                                                 conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 14, 14, 928)  3712        concatenate_39[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 14, 14, 928)  0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 14, 14, 128)  118784      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 14, 14, 128)  512         conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 14, 14, 128)  0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 14, 14, 32)   36864       activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_40 (Concatenate)    (None, 14, 14, 960)  0           transition_layer_2[0][0]         \n",
      "                                                                 conv2d_41[0][0]                  \n",
      "                                                                 conv2d_43[0][0]                  \n",
      "                                                                 conv2d_45[0][0]                  \n",
      "                                                                 conv2d_47[0][0]                  \n",
      "                                                                 conv2d_49[0][0]                  \n",
      "                                                                 conv2d_51[0][0]                  \n",
      "                                                                 conv2d_53[0][0]                  \n",
      "                                                                 conv2d_55[0][0]                  \n",
      "                                                                 conv2d_57[0][0]                  \n",
      "                                                                 conv2d_59[0][0]                  \n",
      "                                                                 conv2d_61[0][0]                  \n",
      "                                                                 conv2d_63[0][0]                  \n",
      "                                                                 conv2d_65[0][0]                  \n",
      "                                                                 conv2d_67[0][0]                  \n",
      "                                                                 conv2d_69[0][0]                  \n",
      "                                                                 conv2d_71[0][0]                  \n",
      "                                                                 conv2d_73[0][0]                  \n",
      "                                                                 conv2d_75[0][0]                  \n",
      "                                                                 conv2d_77[0][0]                  \n",
      "                                                                 conv2d_79[0][0]                  \n",
      "                                                                 conv2d_81[0][0]                  \n",
      "                                                                 conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 14, 14, 960)  3840        concatenate_40[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 14, 14, 960)  0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 14, 14, 128)  122880      activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 14, 14, 128)  512         conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 14, 14, 128)  0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 14, 14, 32)   36864       activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_41 (Concatenate)    (None, 14, 14, 992)  0           transition_layer_2[0][0]         \n",
      "                                                                 conv2d_41[0][0]                  \n",
      "                                                                 conv2d_43[0][0]                  \n",
      "                                                                 conv2d_45[0][0]                  \n",
      "                                                                 conv2d_47[0][0]                  \n",
      "                                                                 conv2d_49[0][0]                  \n",
      "                                                                 conv2d_51[0][0]                  \n",
      "                                                                 conv2d_53[0][0]                  \n",
      "                                                                 conv2d_55[0][0]                  \n",
      "                                                                 conv2d_57[0][0]                  \n",
      "                                                                 conv2d_59[0][0]                  \n",
      "                                                                 conv2d_61[0][0]                  \n",
      "                                                                 conv2d_63[0][0]                  \n",
      "                                                                 conv2d_65[0][0]                  \n",
      "                                                                 conv2d_67[0][0]                  \n",
      "                                                                 conv2d_69[0][0]                  \n",
      "                                                                 conv2d_71[0][0]                  \n",
      "                                                                 conv2d_73[0][0]                  \n",
      "                                                                 conv2d_75[0][0]                  \n",
      "                                                                 conv2d_77[0][0]                  \n",
      "                                                                 conv2d_79[0][0]                  \n",
      "                                                                 conv2d_81[0][0]                  \n",
      "                                                                 conv2d_83[0][0]                  \n",
      "                                                                 conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 14, 14, 992)  3968        concatenate_41[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 14, 14, 992)  0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 14, 14, 128)  126976      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 14, 14, 128)  512         conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 14, 14, 128)  0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 14, 14, 32)   36864       activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_42 (Concatenate)    (None, 14, 14, 1024) 0           transition_layer_2[0][0]         \n",
      "                                                                 conv2d_41[0][0]                  \n",
      "                                                                 conv2d_43[0][0]                  \n",
      "                                                                 conv2d_45[0][0]                  \n",
      "                                                                 conv2d_47[0][0]                  \n",
      "                                                                 conv2d_49[0][0]                  \n",
      "                                                                 conv2d_51[0][0]                  \n",
      "                                                                 conv2d_53[0][0]                  \n",
      "                                                                 conv2d_55[0][0]                  \n",
      "                                                                 conv2d_57[0][0]                  \n",
      "                                                                 conv2d_59[0][0]                  \n",
      "                                                                 conv2d_61[0][0]                  \n",
      "                                                                 conv2d_63[0][0]                  \n",
      "                                                                 conv2d_65[0][0]                  \n",
      "                                                                 conv2d_67[0][0]                  \n",
      "                                                                 conv2d_69[0][0]                  \n",
      "                                                                 conv2d_71[0][0]                  \n",
      "                                                                 conv2d_73[0][0]                  \n",
      "                                                                 conv2d_75[0][0]                  \n",
      "                                                                 conv2d_77[0][0]                  \n",
      "                                                                 conv2d_79[0][0]                  \n",
      "                                                                 conv2d_81[0][0]                  \n",
      "                                                                 conv2d_83[0][0]                  \n",
      "                                                                 conv2d_85[0][0]                  \n",
      "                                                                 conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 14, 14, 1024) 4096        concatenate_42[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 14, 14, 1024) 0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 14, 14, 512)  4718592     activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "transition_layer_3 (AveragePool (None, 7, 7, 512)    0           conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 7, 7, 512)    2048        transition_layer_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 7, 7, 512)    0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 7, 7, 128)    65536       activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 7, 7, 128)    512         conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 7, 7, 128)    0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 7, 7, 32)     36864       activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_43 (Concatenate)    (None, 7, 7, 544)    0           transition_layer_3[0][0]         \n",
      "                                                                 conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 7, 7, 544)    2176        concatenate_43[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 7, 7, 544)    0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 7, 7, 128)    69632       activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 7, 7, 128)    512         conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 7, 7, 128)    0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 7, 7, 32)     36864       activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_44 (Concatenate)    (None, 7, 7, 576)    0           transition_layer_3[0][0]         \n",
      "                                                                 conv2d_90[0][0]                  \n",
      "                                                                 conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 7, 7, 576)    2304        concatenate_44[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 7, 7, 576)    0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 7, 7, 128)    73728       activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 7, 7, 128)    512         conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, 7, 7, 128)    0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 7, 7, 32)     36864       activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_45 (Concatenate)    (None, 7, 7, 608)    0           transition_layer_3[0][0]         \n",
      "                                                                 conv2d_90[0][0]                  \n",
      "                                                                 conv2d_92[0][0]                  \n",
      "                                                                 conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNo (None, 7, 7, 608)    2432        concatenate_45[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_95 (Activation)      (None, 7, 7, 608)    0           batch_normalization_95[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, 7, 7, 128)    77824       activation_95[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNo (None, 7, 7, 128)    512         conv2d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_96 (Activation)      (None, 7, 7, 128)    0           batch_normalization_96[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, 7, 7, 32)     36864       activation_96[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_46 (Concatenate)    (None, 7, 7, 640)    0           transition_layer_3[0][0]         \n",
      "                                                                 conv2d_90[0][0]                  \n",
      "                                                                 conv2d_92[0][0]                  \n",
      "                                                                 conv2d_94[0][0]                  \n",
      "                                                                 conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNo (None, 7, 7, 640)    2560        concatenate_46[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_97 (Activation)      (None, 7, 7, 640)    0           batch_normalization_97[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, 7, 7, 128)    81920       activation_97[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNo (None, 7, 7, 128)    512         conv2d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_98 (Activation)      (None, 7, 7, 128)    0           batch_normalization_98[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, 7, 7, 32)     36864       activation_98[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_47 (Concatenate)    (None, 7, 7, 672)    0           transition_layer_3[0][0]         \n",
      "                                                                 conv2d_90[0][0]                  \n",
      "                                                                 conv2d_92[0][0]                  \n",
      "                                                                 conv2d_94[0][0]                  \n",
      "                                                                 conv2d_96[0][0]                  \n",
      "                                                                 conv2d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_99 (BatchNo (None, 7, 7, 672)    2688        concatenate_47[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_99 (Activation)      (None, 7, 7, 672)    0           batch_normalization_99[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)              (None, 7, 7, 128)    86016       activation_99[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_100 (BatchN (None, 7, 7, 128)    512         conv2d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_100 (Activation)     (None, 7, 7, 128)    0           batch_normalization_100[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)             (None, 7, 7, 32)     36864       activation_100[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_48 (Concatenate)    (None, 7, 7, 704)    0           transition_layer_3[0][0]         \n",
      "                                                                 conv2d_90[0][0]                  \n",
      "                                                                 conv2d_92[0][0]                  \n",
      "                                                                 conv2d_94[0][0]                  \n",
      "                                                                 conv2d_96[0][0]                  \n",
      "                                                                 conv2d_98[0][0]                  \n",
      "                                                                 conv2d_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_101 (BatchN (None, 7, 7, 704)    2816        concatenate_48[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_101 (Activation)     (None, 7, 7, 704)    0           batch_normalization_101[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_101 (Conv2D)             (None, 7, 7, 128)    90112       activation_101[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_102 (BatchN (None, 7, 7, 128)    512         conv2d_101[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_102 (Activation)     (None, 7, 7, 128)    0           batch_normalization_102[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_102 (Conv2D)             (None, 7, 7, 32)     36864       activation_102[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_49 (Concatenate)    (None, 7, 7, 736)    0           transition_layer_3[0][0]         \n",
      "                                                                 conv2d_90[0][0]                  \n",
      "                                                                 conv2d_92[0][0]                  \n",
      "                                                                 conv2d_94[0][0]                  \n",
      "                                                                 conv2d_96[0][0]                  \n",
      "                                                                 conv2d_98[0][0]                  \n",
      "                                                                 conv2d_100[0][0]                 \n",
      "                                                                 conv2d_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_103 (BatchN (None, 7, 7, 736)    2944        concatenate_49[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_103 (Activation)     (None, 7, 7, 736)    0           batch_normalization_103[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_103 (Conv2D)             (None, 7, 7, 128)    94208       activation_103[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_104 (BatchN (None, 7, 7, 128)    512         conv2d_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_104 (Activation)     (None, 7, 7, 128)    0           batch_normalization_104[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_104 (Conv2D)             (None, 7, 7, 32)     36864       activation_104[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_50 (Concatenate)    (None, 7, 7, 768)    0           transition_layer_3[0][0]         \n",
      "                                                                 conv2d_90[0][0]                  \n",
      "                                                                 conv2d_92[0][0]                  \n",
      "                                                                 conv2d_94[0][0]                  \n",
      "                                                                 conv2d_96[0][0]                  \n",
      "                                                                 conv2d_98[0][0]                  \n",
      "                                                                 conv2d_100[0][0]                 \n",
      "                                                                 conv2d_102[0][0]                 \n",
      "                                                                 conv2d_104[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_105 (BatchN (None, 7, 7, 768)    3072        concatenate_50[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_105 (Activation)     (None, 7, 7, 768)    0           batch_normalization_105[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_105 (Conv2D)             (None, 7, 7, 128)    98304       activation_105[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_106 (BatchN (None, 7, 7, 128)    512         conv2d_105[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_106 (Activation)     (None, 7, 7, 128)    0           batch_normalization_106[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_106 (Conv2D)             (None, 7, 7, 32)     36864       activation_106[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_51 (Concatenate)    (None, 7, 7, 800)    0           transition_layer_3[0][0]         \n",
      "                                                                 conv2d_90[0][0]                  \n",
      "                                                                 conv2d_92[0][0]                  \n",
      "                                                                 conv2d_94[0][0]                  \n",
      "                                                                 conv2d_96[0][0]                  \n",
      "                                                                 conv2d_98[0][0]                  \n",
      "                                                                 conv2d_100[0][0]                 \n",
      "                                                                 conv2d_102[0][0]                 \n",
      "                                                                 conv2d_104[0][0]                 \n",
      "                                                                 conv2d_106[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_107 (BatchN (None, 7, 7, 800)    3200        concatenate_51[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_107 (Activation)     (None, 7, 7, 800)    0           batch_normalization_107[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_107 (Conv2D)             (None, 7, 7, 128)    102400      activation_107[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_108 (BatchN (None, 7, 7, 128)    512         conv2d_107[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_108 (Activation)     (None, 7, 7, 128)    0           batch_normalization_108[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_108 (Conv2D)             (None, 7, 7, 32)     36864       activation_108[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_52 (Concatenate)    (None, 7, 7, 832)    0           transition_layer_3[0][0]         \n",
      "                                                                 conv2d_90[0][0]                  \n",
      "                                                                 conv2d_92[0][0]                  \n",
      "                                                                 conv2d_94[0][0]                  \n",
      "                                                                 conv2d_96[0][0]                  \n",
      "                                                                 conv2d_98[0][0]                  \n",
      "                                                                 conv2d_100[0][0]                 \n",
      "                                                                 conv2d_102[0][0]                 \n",
      "                                                                 conv2d_104[0][0]                 \n",
      "                                                                 conv2d_106[0][0]                 \n",
      "                                                                 conv2d_108[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_109 (BatchN (None, 7, 7, 832)    3328        concatenate_52[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_109 (Activation)     (None, 7, 7, 832)    0           batch_normalization_109[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_109 (Conv2D)             (None, 7, 7, 128)    106496      activation_109[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_110 (BatchN (None, 7, 7, 128)    512         conv2d_109[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_110 (Activation)     (None, 7, 7, 128)    0           batch_normalization_110[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_110 (Conv2D)             (None, 7, 7, 32)     36864       activation_110[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_53 (Concatenate)    (None, 7, 7, 864)    0           transition_layer_3[0][0]         \n",
      "                                                                 conv2d_90[0][0]                  \n",
      "                                                                 conv2d_92[0][0]                  \n",
      "                                                                 conv2d_94[0][0]                  \n",
      "                                                                 conv2d_96[0][0]                  \n",
      "                                                                 conv2d_98[0][0]                  \n",
      "                                                                 conv2d_100[0][0]                 \n",
      "                                                                 conv2d_102[0][0]                 \n",
      "                                                                 conv2d_104[0][0]                 \n",
      "                                                                 conv2d_106[0][0]                 \n",
      "                                                                 conv2d_108[0][0]                 \n",
      "                                                                 conv2d_110[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_111 (BatchN (None, 7, 7, 864)    3456        concatenate_53[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_111 (Activation)     (None, 7, 7, 864)    0           batch_normalization_111[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_111 (Conv2D)             (None, 7, 7, 128)    110592      activation_111[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_112 (BatchN (None, 7, 7, 128)    512         conv2d_111[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_112 (Activation)     (None, 7, 7, 128)    0           batch_normalization_112[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_112 (Conv2D)             (None, 7, 7, 32)     36864       activation_112[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_54 (Concatenate)    (None, 7, 7, 896)    0           transition_layer_3[0][0]         \n",
      "                                                                 conv2d_90[0][0]                  \n",
      "                                                                 conv2d_92[0][0]                  \n",
      "                                                                 conv2d_94[0][0]                  \n",
      "                                                                 conv2d_96[0][0]                  \n",
      "                                                                 conv2d_98[0][0]                  \n",
      "                                                                 conv2d_100[0][0]                 \n",
      "                                                                 conv2d_102[0][0]                 \n",
      "                                                                 conv2d_104[0][0]                 \n",
      "                                                                 conv2d_106[0][0]                 \n",
      "                                                                 conv2d_108[0][0]                 \n",
      "                                                                 conv2d_110[0][0]                 \n",
      "                                                                 conv2d_112[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_113 (BatchN (None, 7, 7, 896)    3584        concatenate_54[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_113 (Activation)     (None, 7, 7, 896)    0           batch_normalization_113[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_113 (Conv2D)             (None, 7, 7, 128)    114688      activation_113[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_114 (BatchN (None, 7, 7, 128)    512         conv2d_113[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_114 (Activation)     (None, 7, 7, 128)    0           batch_normalization_114[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_114 (Conv2D)             (None, 7, 7, 32)     36864       activation_114[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_55 (Concatenate)    (None, 7, 7, 928)    0           transition_layer_3[0][0]         \n",
      "                                                                 conv2d_90[0][0]                  \n",
      "                                                                 conv2d_92[0][0]                  \n",
      "                                                                 conv2d_94[0][0]                  \n",
      "                                                                 conv2d_96[0][0]                  \n",
      "                                                                 conv2d_98[0][0]                  \n",
      "                                                                 conv2d_100[0][0]                 \n",
      "                                                                 conv2d_102[0][0]                 \n",
      "                                                                 conv2d_104[0][0]                 \n",
      "                                                                 conv2d_106[0][0]                 \n",
      "                                                                 conv2d_108[0][0]                 \n",
      "                                                                 conv2d_110[0][0]                 \n",
      "                                                                 conv2d_112[0][0]                 \n",
      "                                                                 conv2d_114[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_115 (BatchN (None, 7, 7, 928)    3712        concatenate_55[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_115 (Activation)     (None, 7, 7, 928)    0           batch_normalization_115[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_115 (Conv2D)             (None, 7, 7, 128)    118784      activation_115[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_116 (BatchN (None, 7, 7, 128)    512         conv2d_115[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_116 (Activation)     (None, 7, 7, 128)    0           batch_normalization_116[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_116 (Conv2D)             (None, 7, 7, 32)     36864       activation_116[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_56 (Concatenate)    (None, 7, 7, 960)    0           transition_layer_3[0][0]         \n",
      "                                                                 conv2d_90[0][0]                  \n",
      "                                                                 conv2d_92[0][0]                  \n",
      "                                                                 conv2d_94[0][0]                  \n",
      "                                                                 conv2d_96[0][0]                  \n",
      "                                                                 conv2d_98[0][0]                  \n",
      "                                                                 conv2d_100[0][0]                 \n",
      "                                                                 conv2d_102[0][0]                 \n",
      "                                                                 conv2d_104[0][0]                 \n",
      "                                                                 conv2d_106[0][0]                 \n",
      "                                                                 conv2d_108[0][0]                 \n",
      "                                                                 conv2d_110[0][0]                 \n",
      "                                                                 conv2d_112[0][0]                 \n",
      "                                                                 conv2d_114[0][0]                 \n",
      "                                                                 conv2d_116[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_117 (BatchN (None, 7, 7, 960)    3840        concatenate_56[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_117 (Activation)     (None, 7, 7, 960)    0           batch_normalization_117[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_117 (Conv2D)             (None, 7, 7, 128)    122880      activation_117[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_118 (BatchN (None, 7, 7, 128)    512         conv2d_117[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_118 (Activation)     (None, 7, 7, 128)    0           batch_normalization_118[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_118 (Conv2D)             (None, 7, 7, 32)     36864       activation_118[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_57 (Concatenate)    (None, 7, 7, 992)    0           transition_layer_3[0][0]         \n",
      "                                                                 conv2d_90[0][0]                  \n",
      "                                                                 conv2d_92[0][0]                  \n",
      "                                                                 conv2d_94[0][0]                  \n",
      "                                                                 conv2d_96[0][0]                  \n",
      "                                                                 conv2d_98[0][0]                  \n",
      "                                                                 conv2d_100[0][0]                 \n",
      "                                                                 conv2d_102[0][0]                 \n",
      "                                                                 conv2d_104[0][0]                 \n",
      "                                                                 conv2d_106[0][0]                 \n",
      "                                                                 conv2d_108[0][0]                 \n",
      "                                                                 conv2d_110[0][0]                 \n",
      "                                                                 conv2d_112[0][0]                 \n",
      "                                                                 conv2d_114[0][0]                 \n",
      "                                                                 conv2d_116[0][0]                 \n",
      "                                                                 conv2d_118[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_119 (BatchN (None, 7, 7, 992)    3968        concatenate_57[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_119 (Activation)     (None, 7, 7, 992)    0           batch_normalization_119[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_119 (Conv2D)             (None, 7, 7, 128)    126976      activation_119[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_120 (BatchN (None, 7, 7, 128)    512         conv2d_119[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_120 (Activation)     (None, 7, 7, 128)    0           batch_normalization_120[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_120 (Conv2D)             (None, 7, 7, 32)     36864       activation_120[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_58 (Concatenate)    (None, 7, 7, 1024)   0           transition_layer_3[0][0]         \n",
      "                                                                 conv2d_90[0][0]                  \n",
      "                                                                 conv2d_92[0][0]                  \n",
      "                                                                 conv2d_94[0][0]                  \n",
      "                                                                 conv2d_96[0][0]                  \n",
      "                                                                 conv2d_98[0][0]                  \n",
      "                                                                 conv2d_100[0][0]                 \n",
      "                                                                 conv2d_102[0][0]                 \n",
      "                                                                 conv2d_104[0][0]                 \n",
      "                                                                 conv2d_106[0][0]                 \n",
      "                                                                 conv2d_108[0][0]                 \n",
      "                                                                 conv2d_110[0][0]                 \n",
      "                                                                 conv2d_112[0][0]                 \n",
      "                                                                 conv2d_114[0][0]                 \n",
      "                                                                 conv2d_116[0][0]                 \n",
      "                                                                 conv2d_118[0][0]                 \n",
      "                                                                 conv2d_120[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 1024)         0           concatenate_58[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           10250       global_average_pooling2d_1[0][0] \n",
      "==================================================================================================\n",
      "Total params: 12,548,682\n",
      "Trainable params: 12,467,082\n",
      "Non-trainable params: 81,600\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 케라스\n",
    "\n",
    "import keras\n",
    "\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, Activation, BatchNormalization, concatenate, AveragePooling2D, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "\n",
    "growth_rate = 32\n",
    "theta = 0.5\n",
    "\n",
    "def DenseBlock(x, num):\n",
    "    layer_list = [x]\n",
    "    for i in range(num): # layer 수가 늘어날수록 layer_list에 있는 x에 대해 새로운 x가 concatenate 된다\n",
    "        x1 = BatchNormalization()(x)\n",
    "        x1 = Activation('relu')(x1)\n",
    "        x1 = Conv2D(growth_rate*4, kernel_size=1, padding='same', use_bias=False)(x1)\n",
    "        x1 = BatchNormalization()(x1)\n",
    "        x1 = Activation('relu')(x1)\n",
    "        x1 = Conv2D(growth_rate, kernel_size=3, padding='same', use_bias=False)(x1)\n",
    "        layer_list.append(x1)\n",
    "        x = concatenate(layer_list, axis=-1) # channel에 대해 layer들을 concatenate\n",
    "    return x\n",
    "\n",
    "\n",
    "def Transition_layer(x, name):\n",
    "    num_ch = int(x.get_shape().as_list()[-1] * theta) # theta 비율만큼 channel 수를 줄임\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(num_ch, kernel_size=3, padding='same', use_bias=False)(x)\n",
    "    x = AveragePooling2D(pool_size=2, strides=2, padding='same', name=name)(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "\n",
    "inputs = Input(shape=(224, 224, 3))\n",
    "x = Conv2D(64, kernel_size=7, strides=2, padding='same', use_bias=False)(inputs) # (None,112, 112, 64)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "x = MaxPooling2D(pool_size=3, strides=2, padding='same')(x) # (None,56, 56, 64)\n",
    "\n",
    "x = DenseBlock(x, 6) # (None,56, 56, 256)\n",
    "x = Transition_layer(x, 'transition_layer_1') # (None,28, 28, 128)\n",
    "x = DenseBlock(x, 12) # (None,28, 28, 512)\n",
    "x = Transition_layer(x, 'transition_layer_2') # (None,14, 14, 256)\n",
    "x = DenseBlock(x, 24) # (None,14, 14, 1024)\n",
    "x = Transition_layer(x, 'transition_layer_3') # (None,7, 7, 512)\n",
    "x = DenseBlock(x, 16) # (None,7, 7, 1024)\n",
    "x = GlobalAveragePooling2D()(x) # (None,1024)\n",
    "outputs = Dense(10, activation='softmax')(x) # (None, 10)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 훈련 - 훈련은 CIFAR10. 훈련시키려면 input shape을 (32, 32, 3)으로 해야됨 .\n",
    "\n",
    "from keras.datasets import cifar10\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "num_classes = 10\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_test = to_categorical(y_test, num_classes)\n",
    "\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "optimizer = SGD(lr=0.1, decay=0.001, momentum=0.9, nesterov=True)\n",
    "model.compile(optimizer, loss='categorical_crossentropy', metrics=['acc'])\n",
    "history = model.fit(x_train, y_train, batch_size=256, epochs=90, validation_split=0.2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
