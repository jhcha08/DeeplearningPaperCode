{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 케라스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization, Input, Dense, Dropout, AveragePooling2D, concatenate, Flatten\n",
    "from keras.models import Model\n",
    "from keras import models\n",
    "\n",
    "def inception(x, c_1, c_2a, c_2b, c_3a, c_3b, c_m):\n",
    "    \n",
    "    pre_layer = x\n",
    "    \n",
    "    conv1 = Conv2D(filters = c_1, kernel_size = (1,1), strides = (1,1), padding = 'same', activation = 'relu')(pre_layer)\n",
    "    \n",
    "    conv2 = Conv2D(filters = c_2a, kernel_size = (1,1), strides = (1,1), padding = 'same', activation = 'relu')(pre_layer)\n",
    "    conv2 = Conv2D(filters = c_2b, kernel_size = (3,3), strides = (1,1), padding = 'same', activation = 'relu')(conv2)\n",
    "    \n",
    "    conv3 = Conv2D(filters = c_3a, kernel_size = (1,1), strides = (1,1), padding = 'same', activation = 'relu')(pre_layer)\n",
    "    conv3 = Conv2D(filters = c_3b, kernel_size = (5,5), strides = (1,1), padding = 'same', activation = 'relu')(conv3)\n",
    "    \n",
    "    maxpool = MaxPooling2D(pool_size = (3,3), strides = (1,1), padding = 'same')(pre_layer)\n",
    "    maxconv = Conv2D(filters = c_m, kernel_size = (1,1), strides = (1,1), padding = 'same', activation = 'relu')(maxpool)\n",
    "    \n",
    "    concat = concatenate([conv1, conv2, conv3, maxconv], axis = -1) # [B,W,H,C] 형태로 결과가 나오므로 채널인 'C' 기준으로 concat\n",
    "    \n",
    "    return concat\n",
    "\n",
    "inputs = Input(shape=(224,224,3))\n",
    "\n",
    "x = Conv2D(filters = 64, kernel_size = (7,7), strides = (2,2), padding = 'same', activation = 'relu')(inputs)\n",
    "x = MaxPooling2D(pool_size = (3,3), strides = (2,2), padding = 'same')(x)\n",
    "\n",
    "x = Conv2D(filters = 64, kernel_size = (1,1), strides = (1,1), padding = 'valid', activation = 'relu')(x)\n",
    "x = Conv2D(filters = 192, kernel_size = (3,3), strides = (1,1), padding = 'same', activation = 'relu')(x)\n",
    "x = MaxPooling2D(pool_size = (3,3), strides = (2,2), padding = 'same')(x)\n",
    "\n",
    "x = inception(x, 64, 96, 128, 16, 32, 32) # 3a\n",
    "x = inception(x, 128, 128, 192, 32, 96, 64) # 3b\n",
    "\n",
    "x = MaxPooling2D(pool_size = (3,3), strides = (2,2), padding = 'same')(x)\n",
    "\n",
    "x = inception(x, 192, 96, 208, 16, 48, 64) # 4a\n",
    "x = inception(x, 160, 112, 224, 24, 64, 64) # 4b\n",
    "\n",
    "aux0 = AveragePooling2D(pool_size = (5,5), strides = (3,3), padding = 'valid')(x)\n",
    "aux0 = Conv2D(filters = 128, kernel_size = (1,1), strides = (3,3), padding = 'same')(aux0)\n",
    "aux0 = Dense(1024, activation = 'relu')(aux0)\n",
    "aux0 = Dense(1024, activation = 'relu')(aux0)\n",
    "softmax0 = Dense(1000, activation = 'softmax')(aux0)\n",
    "\n",
    "x = inception(x, 128, 128, 256, 24, 64, 64) # 4c\n",
    "x = inception(x, 112, 144, 288, 32, 64, 64) # 4d\n",
    "x = inception(x, 256, 160, 320, 32, 128, 128) # 4e\n",
    "\n",
    "aux1 = AveragePooling2D(pool_size = (5,5), strides = (3,3), padding = 'valid')(x)\n",
    "aux1 = Conv2D(filters = 128, kernel_size = (1,1), strides = (3,3), padding = 'same')(aux1)\n",
    "aux1 = Dense(1024, activation = 'relu')(aux1)\n",
    "aux1 = Dense(1024, activation = 'relu')(aux1)\n",
    "softmax1 = Dense(1000, activation = 'softmax')(aux1)\n",
    "\n",
    "x = MaxPooling2D(pool_size = (3,3), strides = (2,2), padding = 'same')(x)\n",
    "\n",
    "x = inception(x, 256, 160, 320, 32, 128, 128) # 5a\n",
    "x = inception(x, 384, 192, 384, 48, 128, 128) # 5b\n",
    "\n",
    "x = AveragePooling2D(pool_size=(7,7), strides = (1,1), padding = 'valid')(x)\n",
    "x = Dropout(0.4)(x)\n",
    "x = Flatten()(x)\n",
    "\n",
    "outputs = Dense(1000, activation = 'softmax')(x)\n",
    "\n",
    "model = Model(inputs = inputs, outputs = [aux0, aux1, outputs])\n",
    "model.summary()\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', loss_weights=[0.3,0.3,1.0]) \n",
    "\n",
    "from IPython.display import SVG\n",
    "from keras.utils import model_to_dot\n",
    "\n",
    "SVG(model_to_dot(model, dpi=50).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 파이토치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, kernel_size, stride, padding):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        \n",
    "        self.conv = nn.Conv2d(in_ch, out_ch, kernel_size, stride, padding, bias=False)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.conv(x)\n",
    "        out = self.relu(x)\n",
    "        \n",
    "        return out\n",
    "\n",
    "    \n",
    "class Inception(nn.Module):\n",
    "    def __init__(self, in_ch, ch_1x1_br1, ch_1x1_br2, ch_3x3_br2, ch_1x1_br3, ch_5x5_br3, ch_pool): # Inception(3a) 예시\n",
    "        super(Inception, self).__init__()\n",
    "        \n",
    "        self.branch_1x1 = nn.Sequential(\n",
    "            ConvBlock(in_ch, ch_1x1_br1, kernel_size=1, stride=1, padding=0))       # in_ch = 192, ch_1x1_br1 = 64\n",
    "        \n",
    "        self.branch_3x3 = nn.Sequential(\n",
    "            ConvBlock(in_ch, ch_1x1_br2, kernel_size=1, stride=1, padding=0),       # in_ch = 192, ch_1x1_br2 = 96\n",
    "            ConvBlock(ch_1x1_br2, ch_3x3_br2, kernel_size=3, stride=1, padding=1))  # ch_1x1_br2 = 96, ch_3x3_br2 = 128\n",
    "        \n",
    "        self.branch_5x5 = nn.Sequential(\n",
    "            ConvBlock(in_ch, ch_1x1_br3, kernel_size=1, stride=1, padding=0),       # in_ch = 192, ch_1x1_br3 = 16\n",
    "            ConvBlock(ch_1x1_br3, ch_5x5_br3, kernel_size=3, stride=1, padding=1))  # ch_1x1_br3 = 16, ch_5x5_br3 = 32\n",
    "        \n",
    "        self.branch_pool = nn.Sequential(\n",
    "            nn.MaxPool2d(kernel_size = 3, stride = 1, padding = 1),                 \n",
    "            ConvBlock(in_ch, ch_pool, kernel_size=1, stride=1, padding=0))          # in_ch = 192, ch_pool = 32\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x_1x1 = self.branch_1x1(x)\n",
    "        x_3x3 = self.branch_3x3(x)\n",
    "        x_5x5 = self.branch_5x5(x)\n",
    "        x_pool = self.branch_pool(x)\n",
    "        \n",
    "        return torch.cat((x_1x1, x_3x3, x_5x5, x_pool), dim=1)\n",
    "        \n",
    "\n",
    "class GoogLeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GoogLeNet, self).__init__()\n",
    "        \n",
    "        self.conv1 = ConvBlock(3, 64, kernel_size=7, stride=2, padding=3)\n",
    "        \n",
    "        self.conv2_1 = ConvBlock(64, 192, kernel_size=1, stride=1, padding=0)\n",
    "        self.conv2_2 = ConvBlock(192, 192, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        self.inception_3a = Inception(192, 64, 96, 128, 16, 32, 32)\n",
    "        self.inception_3b = Inception(256, 128, 128, 192, 32, 96, 64)\n",
    "        \n",
    "        self.inception_4a = Inception(480, 192, 96, 208, 16, 48, 64)\n",
    "        self.inception_4b = Inception(512, 160, 112, 224, 24, 64, 64)\n",
    "        self.inception_4c = Inception(512, 128, 128, 256, 24, 64, 64)\n",
    "        self.inception_4d = Inception(512, 112, 144, 288, 32, 64, 64)\n",
    "        self.inception_4e = Inception(528, 256, 160, 320, 32, 128, 128)\n",
    "        \n",
    "        self.inception_5a = Inception(832, 256, 160, 320, 32, 128, 128)\n",
    "        self.inception_5b = Inception(832, 384, 192, 384, 48, 128, 128)\n",
    "        \n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.avgpool_aux = nn.AvgPool2d(kernel_size=5, stride=3, padding=1)\n",
    "        self.avgpool_final = nn.AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.4)\n",
    "        \n",
    "        self.conv_aux0 = ConvBlock(512, 1024, kernel_size = 1, stride = 1, padding = 0) # 1024는 임의의 숫자\n",
    "        \n",
    "        self.linear_aux0_1 = nn.Linear(16384, 4096) # 4096은 임의의 숫자\n",
    "        self.linear_aux0_2 = nn.Linear(4096, 1000)\n",
    "        \n",
    "        self.conv_aux1 = ConvBlock(528, 1024, kernel_size = 1, stride = 1, padding = 0) # 1024는 임의의 숫자\n",
    "        \n",
    "        # aux0에 쓰인 Linear 레이어와 같지만 안 헷갈리려고 두 개 적음        \n",
    "        self.linear_aux1_1 = nn.Linear(16384, 4096)\n",
    "        self.linear_aux1_2 = nn.Linear(4096, 1000)  \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        \n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        x = self.conv2_1(x)\n",
    "        x = self.conv2_2(x)\n",
    "        \n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        x = self.inception_3a(x)\n",
    "        x = self.inception_3b(x)\n",
    "        \n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        x = self.inception_4a(x)\n",
    "        \n",
    "        aux0 = self.avgpool_aux(x)\n",
    "        aux0 = self.conv_aux0(aux0)\n",
    "        aux0 = aux0.view(aux0.size(0),-1)\n",
    "        aux0 = self.linear_aux0_1(aux0)\n",
    "        aux0 = self.linear_aux0_2(aux0)\n",
    "        \n",
    "        x = self.inception_4b(x)\n",
    "        x = self.inception_4c(x)\n",
    "        x = self.inception_4d(x)\n",
    "        \n",
    "        aux1 = self.avgpool_aux(x)\n",
    "        aux1 = self.conv_aux1(aux1)\n",
    "        aux1 = aux1.view(aux1.size(0),-1)\n",
    "        aux1 = self.linear_aux1_1(aux1)\n",
    "        aux1 = self.linear_aux1_2(aux1)\n",
    "    \n",
    "        x = self.inception_4e(x)\n",
    "        \n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        x = self.inception_5a(x)\n",
    "        x = self.inception_5b(x)\n",
    "        \n",
    "        x = self.avgpool_final(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        return x, aux0, aux1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
      "              ReLU-2         [-1, 64, 112, 112]               0\n",
      "         ConvBlock-3         [-1, 64, 112, 112]               0\n",
      "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
      "            Conv2d-5          [-1, 192, 56, 56]          12,288\n",
      "              ReLU-6          [-1, 192, 56, 56]               0\n",
      "         ConvBlock-7          [-1, 192, 56, 56]               0\n",
      "            Conv2d-8          [-1, 192, 56, 56]         331,776\n",
      "              ReLU-9          [-1, 192, 56, 56]               0\n",
      "        ConvBlock-10          [-1, 192, 56, 56]               0\n",
      "        MaxPool2d-11          [-1, 192, 28, 28]               0\n",
      "           Conv2d-12           [-1, 64, 28, 28]          12,288\n",
      "             ReLU-13           [-1, 64, 28, 28]               0\n",
      "        ConvBlock-14           [-1, 64, 28, 28]               0\n",
      "           Conv2d-15           [-1, 96, 28, 28]          18,432\n",
      "             ReLU-16           [-1, 96, 28, 28]               0\n",
      "        ConvBlock-17           [-1, 96, 28, 28]               0\n",
      "           Conv2d-18          [-1, 128, 28, 28]         110,592\n",
      "             ReLU-19          [-1, 128, 28, 28]               0\n",
      "        ConvBlock-20          [-1, 128, 28, 28]               0\n",
      "           Conv2d-21           [-1, 16, 28, 28]           3,072\n",
      "             ReLU-22           [-1, 16, 28, 28]               0\n",
      "        ConvBlock-23           [-1, 16, 28, 28]               0\n",
      "           Conv2d-24           [-1, 32, 28, 28]           4,608\n",
      "             ReLU-25           [-1, 32, 28, 28]               0\n",
      "        ConvBlock-26           [-1, 32, 28, 28]               0\n",
      "        MaxPool2d-27          [-1, 192, 28, 28]               0\n",
      "           Conv2d-28           [-1, 32, 28, 28]           6,144\n",
      "             ReLU-29           [-1, 32, 28, 28]               0\n",
      "        ConvBlock-30           [-1, 32, 28, 28]               0\n",
      "        Inception-31          [-1, 256, 28, 28]               0\n",
      "           Conv2d-32          [-1, 128, 28, 28]          32,768\n",
      "             ReLU-33          [-1, 128, 28, 28]               0\n",
      "        ConvBlock-34          [-1, 128, 28, 28]               0\n",
      "           Conv2d-35          [-1, 128, 28, 28]          32,768\n",
      "             ReLU-36          [-1, 128, 28, 28]               0\n",
      "        ConvBlock-37          [-1, 128, 28, 28]               0\n",
      "           Conv2d-38          [-1, 192, 28, 28]         221,184\n",
      "             ReLU-39          [-1, 192, 28, 28]               0\n",
      "        ConvBlock-40          [-1, 192, 28, 28]               0\n",
      "           Conv2d-41           [-1, 32, 28, 28]           8,192\n",
      "             ReLU-42           [-1, 32, 28, 28]               0\n",
      "        ConvBlock-43           [-1, 32, 28, 28]               0\n",
      "           Conv2d-44           [-1, 96, 28, 28]          27,648\n",
      "             ReLU-45           [-1, 96, 28, 28]               0\n",
      "        ConvBlock-46           [-1, 96, 28, 28]               0\n",
      "        MaxPool2d-47          [-1, 256, 28, 28]               0\n",
      "           Conv2d-48           [-1, 64, 28, 28]          16,384\n",
      "             ReLU-49           [-1, 64, 28, 28]               0\n",
      "        ConvBlock-50           [-1, 64, 28, 28]               0\n",
      "        Inception-51          [-1, 480, 28, 28]               0\n",
      "        MaxPool2d-52          [-1, 480, 14, 14]               0\n",
      "           Conv2d-53          [-1, 192, 14, 14]          92,160\n",
      "             ReLU-54          [-1, 192, 14, 14]               0\n",
      "        ConvBlock-55          [-1, 192, 14, 14]               0\n",
      "           Conv2d-56           [-1, 96, 14, 14]          46,080\n",
      "             ReLU-57           [-1, 96, 14, 14]               0\n",
      "        ConvBlock-58           [-1, 96, 14, 14]               0\n",
      "           Conv2d-59          [-1, 208, 14, 14]         179,712\n",
      "             ReLU-60          [-1, 208, 14, 14]               0\n",
      "        ConvBlock-61          [-1, 208, 14, 14]               0\n",
      "           Conv2d-62           [-1, 16, 14, 14]           7,680\n",
      "             ReLU-63           [-1, 16, 14, 14]               0\n",
      "        ConvBlock-64           [-1, 16, 14, 14]               0\n",
      "           Conv2d-65           [-1, 48, 14, 14]           6,912\n",
      "             ReLU-66           [-1, 48, 14, 14]               0\n",
      "        ConvBlock-67           [-1, 48, 14, 14]               0\n",
      "        MaxPool2d-68          [-1, 480, 14, 14]               0\n",
      "           Conv2d-69           [-1, 64, 14, 14]          30,720\n",
      "             ReLU-70           [-1, 64, 14, 14]               0\n",
      "        ConvBlock-71           [-1, 64, 14, 14]               0\n",
      "        Inception-72          [-1, 512, 14, 14]               0\n",
      "        AvgPool2d-73            [-1, 512, 4, 4]               0\n",
      "           Conv2d-74           [-1, 1024, 4, 4]         524,288\n",
      "             ReLU-75           [-1, 1024, 4, 4]               0\n",
      "        ConvBlock-76           [-1, 1024, 4, 4]               0\n",
      "           Linear-77                 [-1, 4096]      67,112,960\n",
      "           Linear-78                 [-1, 1000]       4,097,000\n",
      "           Conv2d-79          [-1, 160, 14, 14]          81,920\n",
      "             ReLU-80          [-1, 160, 14, 14]               0\n",
      "        ConvBlock-81          [-1, 160, 14, 14]               0\n",
      "           Conv2d-82          [-1, 112, 14, 14]          57,344\n",
      "             ReLU-83          [-1, 112, 14, 14]               0\n",
      "        ConvBlock-84          [-1, 112, 14, 14]               0\n",
      "           Conv2d-85          [-1, 224, 14, 14]         225,792\n",
      "             ReLU-86          [-1, 224, 14, 14]               0\n",
      "        ConvBlock-87          [-1, 224, 14, 14]               0\n",
      "           Conv2d-88           [-1, 24, 14, 14]          12,288\n",
      "             ReLU-89           [-1, 24, 14, 14]               0\n",
      "        ConvBlock-90           [-1, 24, 14, 14]               0\n",
      "           Conv2d-91           [-1, 64, 14, 14]          13,824\n",
      "             ReLU-92           [-1, 64, 14, 14]               0\n",
      "        ConvBlock-93           [-1, 64, 14, 14]               0\n",
      "        MaxPool2d-94          [-1, 512, 14, 14]               0\n",
      "           Conv2d-95           [-1, 64, 14, 14]          32,768\n",
      "             ReLU-96           [-1, 64, 14, 14]               0\n",
      "        ConvBlock-97           [-1, 64, 14, 14]               0\n",
      "        Inception-98          [-1, 512, 14, 14]               0\n",
      "           Conv2d-99          [-1, 128, 14, 14]          65,536\n",
      "            ReLU-100          [-1, 128, 14, 14]               0\n",
      "       ConvBlock-101          [-1, 128, 14, 14]               0\n",
      "          Conv2d-102          [-1, 128, 14, 14]          65,536\n",
      "            ReLU-103          [-1, 128, 14, 14]               0\n",
      "       ConvBlock-104          [-1, 128, 14, 14]               0\n",
      "          Conv2d-105          [-1, 256, 14, 14]         294,912\n",
      "            ReLU-106          [-1, 256, 14, 14]               0\n",
      "       ConvBlock-107          [-1, 256, 14, 14]               0\n",
      "          Conv2d-108           [-1, 24, 14, 14]          12,288\n",
      "            ReLU-109           [-1, 24, 14, 14]               0\n",
      "       ConvBlock-110           [-1, 24, 14, 14]               0\n",
      "          Conv2d-111           [-1, 64, 14, 14]          13,824\n",
      "            ReLU-112           [-1, 64, 14, 14]               0\n",
      "       ConvBlock-113           [-1, 64, 14, 14]               0\n",
      "       MaxPool2d-114          [-1, 512, 14, 14]               0\n",
      "          Conv2d-115           [-1, 64, 14, 14]          32,768\n",
      "            ReLU-116           [-1, 64, 14, 14]               0\n",
      "       ConvBlock-117           [-1, 64, 14, 14]               0\n",
      "       Inception-118          [-1, 512, 14, 14]               0\n",
      "          Conv2d-119          [-1, 112, 14, 14]          57,344\n",
      "            ReLU-120          [-1, 112, 14, 14]               0\n",
      "       ConvBlock-121          [-1, 112, 14, 14]               0\n",
      "          Conv2d-122          [-1, 144, 14, 14]          73,728\n",
      "            ReLU-123          [-1, 144, 14, 14]               0\n",
      "       ConvBlock-124          [-1, 144, 14, 14]               0\n",
      "          Conv2d-125          [-1, 288, 14, 14]         373,248\n",
      "            ReLU-126          [-1, 288, 14, 14]               0\n",
      "       ConvBlock-127          [-1, 288, 14, 14]               0\n",
      "          Conv2d-128           [-1, 32, 14, 14]          16,384\n",
      "            ReLU-129           [-1, 32, 14, 14]               0\n",
      "       ConvBlock-130           [-1, 32, 14, 14]               0\n",
      "          Conv2d-131           [-1, 64, 14, 14]          18,432\n",
      "            ReLU-132           [-1, 64, 14, 14]               0\n",
      "       ConvBlock-133           [-1, 64, 14, 14]               0\n",
      "       MaxPool2d-134          [-1, 512, 14, 14]               0\n",
      "          Conv2d-135           [-1, 64, 14, 14]          32,768\n",
      "            ReLU-136           [-1, 64, 14, 14]               0\n",
      "       ConvBlock-137           [-1, 64, 14, 14]               0\n",
      "       Inception-138          [-1, 528, 14, 14]               0\n",
      "       AvgPool2d-139            [-1, 528, 4, 4]               0\n",
      "          Conv2d-140           [-1, 1024, 4, 4]         540,672\n",
      "            ReLU-141           [-1, 1024, 4, 4]               0\n",
      "       ConvBlock-142           [-1, 1024, 4, 4]               0\n",
      "          Linear-143                 [-1, 4096]      67,112,960\n",
      "          Linear-144                 [-1, 1000]       4,097,000\n",
      "          Conv2d-145          [-1, 256, 14, 14]         135,168\n",
      "            ReLU-146          [-1, 256, 14, 14]               0\n",
      "       ConvBlock-147          [-1, 256, 14, 14]               0\n",
      "          Conv2d-148          [-1, 160, 14, 14]          84,480\n",
      "            ReLU-149          [-1, 160, 14, 14]               0\n",
      "       ConvBlock-150          [-1, 160, 14, 14]               0\n",
      "          Conv2d-151          [-1, 320, 14, 14]         460,800\n",
      "            ReLU-152          [-1, 320, 14, 14]               0\n",
      "       ConvBlock-153          [-1, 320, 14, 14]               0\n",
      "          Conv2d-154           [-1, 32, 14, 14]          16,896\n",
      "            ReLU-155           [-1, 32, 14, 14]               0\n",
      "       ConvBlock-156           [-1, 32, 14, 14]               0\n",
      "          Conv2d-157          [-1, 128, 14, 14]          36,864\n",
      "            ReLU-158          [-1, 128, 14, 14]               0\n",
      "       ConvBlock-159          [-1, 128, 14, 14]               0\n",
      "       MaxPool2d-160          [-1, 528, 14, 14]               0\n",
      "          Conv2d-161          [-1, 128, 14, 14]          67,584\n",
      "            ReLU-162          [-1, 128, 14, 14]               0\n",
      "       ConvBlock-163          [-1, 128, 14, 14]               0\n",
      "       Inception-164          [-1, 832, 14, 14]               0\n",
      "       MaxPool2d-165            [-1, 832, 7, 7]               0\n",
      "          Conv2d-166            [-1, 256, 7, 7]         212,992\n",
      "            ReLU-167            [-1, 256, 7, 7]               0\n",
      "       ConvBlock-168            [-1, 256, 7, 7]               0\n",
      "          Conv2d-169            [-1, 160, 7, 7]         133,120\n",
      "            ReLU-170            [-1, 160, 7, 7]               0\n",
      "       ConvBlock-171            [-1, 160, 7, 7]               0\n",
      "          Conv2d-172            [-1, 320, 7, 7]         460,800\n",
      "            ReLU-173            [-1, 320, 7, 7]               0\n",
      "       ConvBlock-174            [-1, 320, 7, 7]               0\n",
      "          Conv2d-175             [-1, 32, 7, 7]          26,624\n",
      "            ReLU-176             [-1, 32, 7, 7]               0\n",
      "       ConvBlock-177             [-1, 32, 7, 7]               0\n",
      "          Conv2d-178            [-1, 128, 7, 7]          36,864\n",
      "            ReLU-179            [-1, 128, 7, 7]               0\n",
      "       ConvBlock-180            [-1, 128, 7, 7]               0\n",
      "       MaxPool2d-181            [-1, 832, 7, 7]               0\n",
      "          Conv2d-182            [-1, 128, 7, 7]         106,496\n",
      "            ReLU-183            [-1, 128, 7, 7]               0\n",
      "       ConvBlock-184            [-1, 128, 7, 7]               0\n",
      "       Inception-185            [-1, 832, 7, 7]               0\n",
      "          Conv2d-186            [-1, 384, 7, 7]         319,488\n",
      "            ReLU-187            [-1, 384, 7, 7]               0\n",
      "       ConvBlock-188            [-1, 384, 7, 7]               0\n",
      "          Conv2d-189            [-1, 192, 7, 7]         159,744\n",
      "            ReLU-190            [-1, 192, 7, 7]               0\n",
      "       ConvBlock-191            [-1, 192, 7, 7]               0\n",
      "          Conv2d-192            [-1, 384, 7, 7]         663,552\n",
      "            ReLU-193            [-1, 384, 7, 7]               0\n",
      "       ConvBlock-194            [-1, 384, 7, 7]               0\n",
      "          Conv2d-195             [-1, 48, 7, 7]          39,936\n",
      "            ReLU-196             [-1, 48, 7, 7]               0\n",
      "       ConvBlock-197             [-1, 48, 7, 7]               0\n",
      "          Conv2d-198            [-1, 128, 7, 7]          55,296\n",
      "            ReLU-199            [-1, 128, 7, 7]               0\n",
      "       ConvBlock-200            [-1, 128, 7, 7]               0\n",
      "       MaxPool2d-201            [-1, 832, 7, 7]               0\n",
      "          Conv2d-202            [-1, 128, 7, 7]         106,496\n",
      "            ReLU-203            [-1, 128, 7, 7]               0\n",
      "       ConvBlock-204            [-1, 128, 7, 7]               0\n",
      "       Inception-205           [-1, 1024, 7, 7]               0\n",
      "       AvgPool2d-206           [-1, 1024, 1, 1]               0\n",
      "         Dropout-207           [-1, 1024, 1, 1]               0\n",
      "================================================================\n",
      "Total params: 149,299,600\n",
      "Trainable params: 149,299,600\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 104.24\n",
      "Params size (MB): 569.53\n",
      "Estimated Total Size (MB): 674.35\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    from torchsummary import summary\n",
    "    model = GoogLeNet()\n",
    "    summary(model, (3, 224, 224))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 옛날에 구현한 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "        \n",
    "class Inception(nn.Module): # padding은 공식 이용해서 계산, stride는 주어짐, 'S'는 'same', 'V'는 'valid'로 간주\n",
    "    \n",
    "    def __init__(self, common_in_ch, o_c1, o_c2a, i_c2, o_c2b, o_c3a, i_c3, o_c3b, o_c4): \n",
    "        super(Inception, self).__init__()\n",
    "        \n",
    "        branch1 = []\n",
    "        branch1 += [nn.Conv2d(in_channels = common_in_ch, out_channels = o_c1, kernel_size = 1, stride = 1, padding = 0),\n",
    "                    nn.ReLU(True)]\n",
    "        \n",
    "        branch2 = []\n",
    "        branch2 += [nn.Conv2d(in_channels = common_in_ch, out_channels = o_c2a, kernel_size = 1, stride = 1, padding = 0),\n",
    "                    nn.ReLU(True),\n",
    "                    nn.Conv2d(in_channels = i_c2, out_channels = o_c2b, kernel_size = 3, stride = 1, padding = 1),\n",
    "                    nn.ReLU(True)]\n",
    "        \n",
    "        branch3 = []\n",
    "        branch3 += [nn.Conv2d(in_channels = common_in_ch, out_channels = o_c3a, kernel_size = 1, stride = 1, padding = 0),\n",
    "                    nn.ReLU(True),\n",
    "                    nn.Conv2d(in_channels = i_c3, out_channels = o_c3b, kernel_size = 5, stride = 1, padding = 2),\n",
    "                    nn.ReLU(True)]\n",
    "        \n",
    "        branch4 = []\n",
    "        branch4 += [nn.MaxPool2d(kernel_size = 3, stride = 1, padding = 1),\n",
    "                    nn.Conv2d(in_channels = common_in_ch, out_channels = o_c4, kernel_size = 1, padding = 0),\n",
    "                    nn.ReLU(True)]\n",
    "        \n",
    "        self.layer1 = nn.Sequential(*branch1)\n",
    "        self.layer2 = nn.Sequential(*branch2)\n",
    "        self.layer3 = nn.Sequential(*branch3)\n",
    "        self.layer4 = nn.Sequential(*branch4)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x1 = self.layer1(x)\n",
    "        x2 = self.layer2(x)\n",
    "        x3 = self.layer3(x)\n",
    "        x4 = self.layer4(x)\n",
    "        \n",
    "        out = torch.cat((x1, x2, x3, x4), dim = 1) # (batchsize, channel, width, height)\n",
    "        \n",
    "        return out\n",
    "\n",
    "class GoogleNet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(GoogleNet, self).__init__()\n",
    "        \n",
    "        layer1 = []\n",
    "        layer1 += [nn.Conv2d(in_channels = 3, out_channels = 64, kernel_size = 7, stride = 2, padding = 3), \n",
    "                   nn.ReLU(True),\n",
    "                   nn.MaxPool2d(kernel_size = 3, stride = 2, padding = 1),\n",
    "                   nn.Conv2d(in_channels = 64, out_channels = 64, kernel_size = 1, stride = 1, padding = 0), # (V)로 표시되서 valid로 간주\n",
    "                   nn.ReLU(True),\n",
    "                   nn.Conv2d(in_channels = 64, out_channels = 192, kernel_size = 3, stride = 1, padding = 1),\n",
    "                   nn.ReLU(True),\n",
    "                   Inception(192, o_c1=64, o_c2a=96, i_c2=96, o_c2b=128, o_c3a=16, i_c3=16, o_c3b=32, o_c4=32),\n",
    "                   Inception(256, 128, 128, 128, 192, 32, 32, 96, 64),\n",
    "                   nn.MaxPool2d(kernel_size = 3, stride = 2, padding = 1),\n",
    "                   Inception(480, 192, 96, 96, 208, 16, 16, 48, 64),\n",
    "                   Inception(512, 160, 112, 112, 224, 24, 24, 64, 64)]\n",
    "        \n",
    "        layer2 = []\n",
    "        layer2 += [Inception(512, 128, 128, 128, 256, 24, 24, 64, 64),\n",
    "                   Inception(512, 112, 144, 144, 288, 32, 32, 64, 64),\n",
    "                   Inception(528, 256, 160, 160, 320, 32, 32, 128, 128)]\n",
    "        \n",
    "        layer3 = []\n",
    "        layer3 += [nn.MaxPool2d(kernel_size = 3, stride = 2, padding = 1),\n",
    "                   Inception(832, 256, 160, 160, 320, 32, 32, 128, 128),\n",
    "                   Inception(832, 384, 192, 192, 384, 48, 48, 128, 128),\n",
    "                   nn.AdaptiveAvgPool2d((7,7)),\n",
    "                   nn.Dropout(0.4)]\n",
    "        \n",
    "        self.layer1 = nn.Sequential(*layer1)\n",
    "        self.layer2 = nn.Sequential(*layer2)\n",
    "        self.layer3 = nn.Sequential(*layer3)\n",
    "        \n",
    "        self.conv = nn.Conv2d(in_channels = 512, out_channels = 1024, kernel_size = 1, stride = 1, padding = 1)\n",
    "        \n",
    "        self.dense1a = nn.Linear(in_features = 65664, out_features = 132096) # 이것들은 모두 keras의 summary를 통해서 알아냈음\n",
    "        self.dense1b = nn.Linear(in_features = 106624, out_features = 132096)\n",
    "        \n",
    "        self.dense2 = nn.Linear(in_features = 132096, out_features = 1049600)\n",
    "        \n",
    "        self.dense3 = nn.Linear(in_features = 1024, out_features = 1000)\n",
    "        \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((5,5)) # AdaptiveAvgPool2d은 이 형태로만, stride와 padding 안들어감\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.layer1(x)\n",
    "        \n",
    "        aux0 = self.avgpool(x)\n",
    "        aux0 = self.conv(aux0)\n",
    "        aux0 = self.dense1a(aux0)\n",
    "        aux0 = self.dense2(aux0)\n",
    "        \n",
    "        x = self.layer2(x)\n",
    "        \n",
    "        aux1 = self.avgpool(x)\n",
    "        aux1 = self.conv(aux1)\n",
    "        aux1 = self.dense1b(aux1)\n",
    "        aux1 = self.dense2(aux1)\n",
    "        \n",
    "        x = self.layer3(x)\n",
    "        x = x.view(x.size(0),-1)\n",
    "        x =  self.dense3(x)\n",
    "        \n",
    "        return x, aux0, aux1\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    from torchsummary import summary\n",
    "    model = GoogleNet()\n",
    "    summary(model, (3, 224, 224))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
